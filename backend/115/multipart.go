// 115ç½‘ç›˜åˆ†ç‰‡ä¸Šä¼ å®žçŽ°
// é‡‡ç”¨å•çº¿ç¨‹é¡ºåºä¸Šä¼ æ¨¡å¼ï¼Œç¡®ä¿ä¸Šä¼ ç¨³å®šæ€§å’ŒSHA1éªŒè¯é€šè¿‡
package _115

import (
	"context"
	"fmt"
	"io"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/aliyun/alibabacloud-oss-go-sdk-v2/oss"
	"github.com/rclone/rclone/backend/115/api"
	"github.com/rclone/rclone/fs"
	"github.com/rclone/rclone/fs/accounting"
	"github.com/rclone/rclone/fs/chunksize"
	"github.com/rclone/rclone/fs/fserrors"
	"github.com/rclone/rclone/lib/atexit"
	"github.com/rclone/rclone/lib/pool"
)

const (
	bufferSize           = 1024 * 1024     // default size of the pages used in the reader
	bufferCacheSize      = 64              // max number of buffers to keep in cache
	bufferCacheFlushTime = 5 * time.Second // flush the cached buffers after this long
)

// bufferPool is a global pool of buffers
var (
	bufferPool     *pool.Pool
	bufferPoolOnce sync.Once
)

// get a buffer pool
func getPool() *pool.Pool {
	bufferPoolOnce.Do(func() {
		ci := fs.GetConfig(context.Background())
		// Initialise the buffer pool when used
		bufferPool = pool.New(bufferCacheFlushTime, bufferSize, bufferCacheSize, ci.UseMmap)
	})
	return bufferPool
}

// NewRW gets a pool.RW using the multipart pool
func NewRW() *pool.RW {
	return pool.NewRW(getPool())
}

// Upload æ‰§è¡Œ115ç½‘ç›˜å•çº¿ç¨‹åˆ†ç‰‡ä¸Šä¼ 
// é‡‡ç”¨é¡ºåºä¸Šä¼ æ¨¡å¼ï¼Œç¡®ä¿ä¸Šä¼ ç¨³å®šæ€§å’ŒSHA1éªŒè¯é€šè¿‡
func (w *ossChunkWriter) Upload(ctx context.Context) (err error) {
	uploadCtx, cancel := context.WithCancel(ctx)
	defer cancel()
	defer atexit.OnError(&err, func() {
		cancel()
		fs.Debugf(w.o, "åˆ†ç‰‡ä¸Šä¼ å–æ¶ˆä¸­...")
		errCancel := w.Abort(ctx)
		if errCancel != nil {
			fs.Debugf(w.o, "å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ å¤±è´¥: %v", errCancel)
		}
	})()

	var (
		finished   = false
		off        int64
		size       = w.size
		chunkSize  = w.chunkSize
		partNum    int64
		totalParts int64
	)

	// è®¡ç®—æ€»åˆ†ç‰‡æ•°ç”¨äºŽè¿›åº¦æ˜¾ç¤º
	if size > 0 {
		totalParts = (size + chunkSize - 1) / chunkSize
	}

	// æ‰‹åŠ¨å¤„ç†accounting
	in, acc := accounting.UnWrapAccounting(w.in)

	fs.Infof(w.o, "å¼€å§‹115ç½‘ç›˜åˆ†ç‰‡ä¸Šä¼ : æ–‡ä»¶å¤§å° %v, åˆ†ç‰‡å¤§å° %v, é¢„è®¡åˆ†ç‰‡æ•° %d",
		fs.SizeSuffix(size), fs.SizeSuffix(chunkSize), totalParts)

	for partNum = 0; !finished; partNum++ {
		// èŽ·å–å†…å­˜ç¼“å†²åŒº
		rw := NewRW()
		if acc != nil {
			rw.SetAccounting(acc.AccountRead)
		}

		// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
		if uploadCtx.Err() != nil {
			_ = rw.Close()
			break
		}

		// è¯»å–åˆ†ç‰‡æ•°æ®
		var n int64
		n, err = io.CopyN(rw, in, chunkSize)
		if err == io.EOF {
			if n == 0 && partNum != 0 { // å¦‚æžœä¸æ˜¯ç¬¬ä¸€ä¸ªåˆ†ç‰‡ä¸”æ²¡æœ‰æ•°æ®ï¼Œåˆ™ç»“æŸ
				_ = rw.Close()
				break
			}
			finished = true
		} else if err != nil {
			_ = rw.Close()
			return fmt.Errorf("è¯»å–åˆ†ç‰‡æ•°æ®å¤±è´¥: %w", err)
		}

		// æ˜¾ç¤ºè¯¦ç»†çš„åˆ†ç‰‡ä¸Šä¼ è¿›åº¦
		currentPart := partNum + 1
		if totalParts > 0 {
			fs.Infof(w.o, "ä¸Šä¼ åˆ†ç‰‡ %d/%d (å¤§å°: %v, åç§»: %v)",
				currentPart, totalParts, fs.SizeSuffix(n), fs.SizeSuffix(off))
		} else {
			fs.Infof(w.o, "ä¸Šä¼ åˆ†ç‰‡ %d (å¤§å°: %v, åç§»: %v)",
				currentPart, fs.SizeSuffix(n), fs.SizeSuffix(off))
		}

		// ä¸Šä¼ å½“å‰åˆ†ç‰‡
		_, err = w.WriteChunk(uploadCtx, int32(partNum), rw)
		_ = rw.Close() // é‡Šæ”¾å†…å­˜ç¼“å†²åŒº

		if err != nil {
			return fmt.Errorf("ä¸Šä¼ åˆ†ç‰‡ %d å¤±è´¥: %w", currentPart, err)
		}

		off += n
	}

	// å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
	err = w.Close(ctx)
	if err != nil {
		return fmt.Errorf("å®Œæˆåˆ†ç‰‡ä¸Šä¼ å¤±è´¥: %w", err)
	}

	return nil
}

var warnStreamUpload sync.Once

// ossChunkWriter 115ç½‘ç›˜åˆ†ç‰‡ä¸Šä¼ å†™å…¥å™¨
// é‡‡ç”¨å•çº¿ç¨‹é¡ºåºä¸Šä¼ æ¨¡å¼
type ossChunkWriter struct {
	chunkSize     int64                              // åˆ†ç‰‡å¤§å°
	size          int64                              // æ–‡ä»¶æ€»å¤§å°
	f             *Fs                                // æ–‡ä»¶ç³»ç»Ÿå®žä¾‹
	o             *Object                            // å¯¹è±¡å®žä¾‹
	in            io.Reader                          // è¾“å…¥æµ
	uploadedParts []oss.UploadPart                   // å·²ä¸Šä¼ çš„åˆ†ç‰‡åˆ—è¡¨
	client        *oss.Client                        // OSSå®¢æˆ·ç«¯
	callback      string                             // 115ç½‘ç›˜å›žè°ƒURL
	callbackVar   string                             // 115ç½‘ç›˜å›žè°ƒå˜é‡
	callbackRes   map[string]any                     // å›žè°ƒç»“æžœ
	imur          *oss.InitiateMultipartUploadResult // åˆ†ç‰‡ä¸Šä¼ åˆå§‹åŒ–ç»“æžœ
}

func (f *Fs) newChunkWriter(ctx context.Context, src fs.ObjectInfo, ui *api.UploadInitInfo, in io.Reader, o *Object, options ...fs.OpenOption) (w *ossChunkWriter, err error) {
	uploadParts := min(max(1, f.opt.MaxUploadParts), maxUploadParts)
	size := src.Size()

	// è®¡ç®—åˆ†ç‰‡å¤§å°
	chunkSize := f.opt.ChunkSize

	// å¤„ç†æœªçŸ¥æ–‡ä»¶å¤§å°çš„æƒ…å†µï¼ˆæµå¼ä¸Šä¼ ï¼‰
	if size == -1 {
		warnStreamUpload.Do(func() {
			fs.Logf(f, "æµå¼ä¸Šä¼ ä½¿ç”¨åˆ†ç‰‡å¤§å° %vï¼Œæœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶ä¸º %v",
				f.opt.ChunkSize, fs.SizeSuffix(int64(chunkSize)*int64(uploadParts)))
		})
	} else {
		chunkSize = chunksize.Calculator(src, size, uploadParts, chunkSize)
	}

	// 115ç½‘ç›˜é‡‡ç”¨å•çº¿ç¨‹åˆ†ç‰‡ä¸Šä¼ æ¨¡å¼ï¼Œç¡®ä¿ç¨³å®šæ€§
	fs.Debugf(f, "115ç½‘ç›˜åˆ†ç‰‡ä¸Šä¼ : æ–‡ä»¶å¤§å° %v, åˆ†ç‰‡å¤§å° %v", fs.SizeSuffix(size), fs.SizeSuffix(int64(chunkSize)))

	w = &ossChunkWriter{
		chunkSize: int64(chunkSize),
		size:      size,
		f:         f,
		o:         o,
		in:        in,
	}

	var client *oss.Client
	client, err = f.newOSSClient()
	if err != nil {
		return nil, fmt.Errorf("failed to create OSS client: %w", err)
	}
	w.client = client

	req := &oss.InitiateMultipartUploadRequest{
		Bucket: oss.Ptr(ui.GetBucket()),
		Key:    oss.Ptr(ui.GetObject()),
	}
	// 115ç½‘ç›˜OSSä½¿ç”¨Sequentialæ¨¡å¼ï¼Œç¡®ä¿åˆ†ç‰‡æŒ‰é¡ºåºå¤„ç†
	req.Parameters = map[string]string{
		"sequential": "",
	}
	// Apply upload options
	for _, option := range options {
		key, value := option.Header()
		lowerKey := strings.ToLower(key)
		switch lowerKey {
		case "":
			// ignore
		case "cache-control":
			req.CacheControl = oss.Ptr(value)
		case "content-disposition":
			req.ContentDisposition = oss.Ptr(value)
		case "content-encoding":
			req.ContentEncoding = oss.Ptr(value)
		case "content-type":
			req.ContentType = oss.Ptr(value)
		}
	}
	// ðŸ”§ ä½¿ç”¨ä¸“ç”¨çš„ä¸Šä¼ è°ƒé€Ÿå™¨ï¼Œä¼˜åŒ–åˆ†ç‰‡ä¸Šä¼ åˆå§‹åŒ–APIè°ƒç”¨é¢‘çŽ‡
	err = w.f.uploadPacer.Call(func() (bool, error) {
		w.imur, err = w.client.InitiateMultipartUpload(ctx, req)
		return w.shouldRetry(ctx, err)
	})
	if err != nil {
		return nil, fmt.Errorf("create multipart upload failed: %w", err)
	}
	w.callback, w.callbackVar = ui.GetCallback(), ui.GetCallbackVar()
	fs.Debugf(w.o, "115ç½‘ç›˜åˆ†ç‰‡ä¸Šä¼ åˆå§‹åŒ–æˆåŠŸ: %q", *w.imur.UploadId)
	return
}

// shouldRetry returns a boolean as to whether this err
// deserve to be retried. It returns the err as a convenience
func (w *ossChunkWriter) shouldRetry(ctx context.Context, err error) (bool, error) {
	if fserrors.ContextError(ctx, &err) {
		return false, err
	}
	if fserrors.ShouldRetry(err) {
		return true, err
	}

	// Since alibabacloud-oss-go-sdk-v2, oss.ServiceError is wrapped by oss.OperationError
	// so we need to unwrap
	if opErr, ok := err.(*oss.OperationError); ok {
		err = opErr.Unwrap()
	}

	switch ossErr := err.(type) {
	case *oss.ServiceError:
		if ossErr.StatusCode == 403 && (ossErr.Code == "InvalidAccessKeyId" || ossErr.Code == "SecurityTokenExpired") {
			// oss: service returned error: StatusCode=403, ErrorCode=InvalidAccessKeyId,
			// ErrorMessage="The OSS Access Key Id you provided does not exist in our records.",

			// oss: service returned error: StatusCode=403, ErrorCode=SecurityTokenExpired,
			// ErrorMessage="The security token you provided has expired."

			// These errors cannot be handled once token is expired. Should update token proactively.
			return false, fserrors.FatalError(err)
		}
	}
	return false, err
}

// addCompletedPart æ·»åŠ å·²å®Œæˆçš„åˆ†ç‰‡åˆ°åˆ—è¡¨
// å•çº¿ç¨‹æ¨¡å¼ä¸‹æŒ‰é¡ºåºæ·»åŠ ï¼Œæ— éœ€å¤æ‚çš„å¹¶å‘æŽ§åˆ¶
func (w *ossChunkWriter) addCompletedPart(part oss.UploadPart) {
	w.uploadedParts = append(w.uploadedParts, part)
}

// WriteChunk will write chunk number with reader bytes, where chunk number >= 0
func (w *ossChunkWriter) WriteChunk(ctx context.Context, chunkNumber int32, reader io.ReadSeeker) (currentChunkSize int64, err error) {
	if chunkNumber < 0 {
		err := fmt.Errorf("invalid chunk number provided: %v", chunkNumber)
		return -1, err
	}

	ossPartNumber := chunkNumber + 1
	var res *oss.UploadPartResult
	// ðŸ”§ ä½¿ç”¨ä¸“ç”¨çš„ä¸Šä¼ è°ƒé€Ÿå™¨ï¼Œä¼˜åŒ–åˆ†ç‰‡ä¸Šä¼ APIè°ƒç”¨é¢‘çŽ‡
	err = w.f.uploadPacer.Call(func() (bool, error) {
		// Discover the size by seeking to the end
		currentChunkSize, err = reader.Seek(0, io.SeekEnd)
		if err != nil {
			return false, err
		}
		// rewind the reader on retry and after reading md5
		_, err := reader.Seek(0, io.SeekStart)
		if err != nil {
			return false, err
		}
		res, err = w.client.UploadPart(ctx, &oss.UploadPartRequest{
			Bucket:     oss.Ptr(*w.imur.Bucket),
			Key:        oss.Ptr(*w.imur.Key),
			UploadId:   w.imur.UploadId,
			PartNumber: ossPartNumber,
			Body:       reader,
		})
		if err != nil {
			if chunkNumber <= 8 {
				return w.shouldRetry(ctx, err)
			}
			// retry all chunks once have done the first few
			return true, err
		}
		return false, nil
	})
	if err != nil {
		return -1, fmt.Errorf("failed to upload chunk %d with %v bytes: %w", ossPartNumber, currentChunkSize, err)
	}

	part := oss.UploadPart{
		PartNumber: ossPartNumber,
		ETag:       res.ETag,
	}
	w.addCompletedPart(part)

	fs.Debugf(w.o, "åˆ†ç‰‡ %d ä¸Šä¼ å®Œæˆ: å¤§å° %v", ossPartNumber, fs.SizeSuffix(currentChunkSize))
	return currentChunkSize, err
}

// Abort the multipart upload
func (w *ossChunkWriter) Abort(ctx context.Context) (err error) {
	// ðŸ”§ ä½¿ç”¨ä¸“ç”¨çš„ä¸Šä¼ è°ƒé€Ÿå™¨ï¼Œä¼˜åŒ–åˆ†ç‰‡ä¸Šä¼ ä¸­æ­¢APIè°ƒç”¨é¢‘çŽ‡
	err = w.f.uploadPacer.Call(func() (bool, error) {
		_, err = w.client.AbortMultipartUpload(ctx, &oss.AbortMultipartUploadRequest{
			Bucket:   oss.Ptr(*w.imur.Bucket),
			Key:      oss.Ptr(*w.imur.Key),
			UploadId: w.imur.UploadId,
		})
		return w.shouldRetry(ctx, err)
	})
	if err != nil {
		return fmt.Errorf("failed to abort multipart upload %q: %w", *w.imur.UploadId, err)
	}
	// w.shutdownRenew()
	fs.Debugf(w.o, "multipart upload: %q aborted", *w.imur.UploadId)
	return
}

// Close å®Œæˆå¹¶ç¡®è®¤åˆ†ç‰‡ä¸Šä¼ 
func (w *ossChunkWriter) Close(ctx context.Context) (err error) {
	// å•çº¿ç¨‹æ¨¡å¼ä¸‹åˆ†ç‰‡å·²æŒ‰é¡ºåºæ·»åŠ ï¼Œä½†ä¸ºä¿é™©èµ·è§ä»è¿›è¡ŒæŽ’åº
	sort.Slice(w.uploadedParts, func(i, j int) bool {
		return w.uploadedParts[i].PartNumber < w.uploadedParts[j].PartNumber
	})

	fs.Infof(w.o, "å‡†å¤‡å®Œæˆåˆ†ç‰‡ä¸Šä¼ : å…± %d ä¸ªåˆ†ç‰‡", len(w.uploadedParts))

	// å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
	var res *oss.CompleteMultipartUploadResult
	req := &oss.CompleteMultipartUploadRequest{
		Bucket:   oss.Ptr(*w.imur.Bucket),
		Key:      oss.Ptr(*w.imur.Key),
		UploadId: w.imur.UploadId,
		CompleteMultipartUpload: &oss.CompleteMultipartUpload{
			Parts: w.uploadedParts,
		},
		Callback:    oss.Ptr(w.callback),
		CallbackVar: oss.Ptr(w.callbackVar),
	}

	// ðŸ”§ ä½¿ç”¨ä¸“ç”¨çš„ä¸Šä¼ è°ƒé€Ÿå™¨ï¼Œä¼˜åŒ–åˆ†ç‰‡ä¸Šä¼ å®ŒæˆAPIè°ƒç”¨é¢‘çŽ‡
	err = w.f.uploadPacer.Call(func() (bool, error) {
		res, err = w.client.CompleteMultipartUpload(ctx, req)
		return w.shouldRetry(ctx, err)
	})
	if err != nil {
		return fmt.Errorf("å®Œæˆåˆ†ç‰‡ä¸Šä¼ å¤±è´¥: %w", err)
	}

	w.callbackRes = res.CallbackResult
	fs.Infof(w.o, "115ç½‘ç›˜åˆ†ç‰‡ä¸Šä¼ å®Œæˆ: %q", *w.imur.UploadId)
	return
}
