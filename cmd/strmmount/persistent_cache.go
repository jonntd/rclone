package strmmount

import (
	"context"
	"crypto/md5"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/rclone/rclone/fs"
	"github.com/rclone/rclone/fs/config"
	"github.com/rclone/rclone/fs/hash"
)

// STRMPersistentCache æŒä¹…åŒ–ç¼“å­˜ç®¡ç†å™¨
type STRMPersistentCache struct {
	mu           sync.RWMutex
	backend      string        // åç«¯ç±»å‹ (123/115)
	remotePath   string        // è¿œç¨‹è·¯å¾„
	configHash   string        // é…ç½®å“ˆå¸Œ
	cacheDir     string        // ç¼“å­˜ç›®å½•
	cacheFile    string        // ç¼“å­˜æ–‡ä»¶è·¯å¾„
	metaFile     string        // å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
	lockFile     string        // é”æ–‡ä»¶è·¯å¾„
	ttl          time.Duration // ç¼“å­˜è¿‡æœŸæ—¶é—´
	enabled      bool          // æ˜¯å¦å¯ç”¨
	lastSync     time.Time     // ä¸Šæ¬¡åŒæ­¥æ—¶é—´
	syncInterval time.Duration // åŒæ­¥é—´éš”
	maxCacheSize int64         // æœ€å¤§ç¼“å­˜å¤§å°
	compression  bool          // æ˜¯å¦å¯ç”¨å‹ç¼©
}

// CacheData ç¼“å­˜æ•°æ®ç»“æ„
type CacheData struct {
	Version     string            `json:"version"`
	Backend     string            `json:"backend"`
	RemotePath  string            `json:"remote_path"`
	ConfigHash  string            `json:"config_hash"`
	CreatedAt   time.Time         `json:"created_at"`
	UpdatedAt   time.Time         `json:"updated_at"`
	ExpiresAt   time.Time         `json:"expires_at"`
	FileCount   int               `json:"file_count"`
	TotalSize   int64             `json:"total_size"`
	Directories []CachedDirectory `json:"directories"`
	Metadata    CacheMetadata     `json:"metadata"`
}

// CachedDirectory ç¼“å­˜çš„ç›®å½•ä¿¡æ¯
type CachedDirectory struct {
	Path      string       `json:"path"`
	DirID     string       `json:"dir_id"`
	ModTime   time.Time    `json:"mod_time"`
	FileCount int          `json:"file_count"`
	TotalSize int64        `json:"total_size"`
	Files     []CachedFile `json:"files"`
}

// CachedFile ç¼“å­˜çš„æ–‡ä»¶ä¿¡æ¯
type CachedFile struct {
	Name     string    `json:"name"`
	Size     int64     `json:"size"`
	ModTime  time.Time `json:"mod_time"`
	FileID   string    `json:"file_id"`
	PickCode string    `json:"pick_code"`
	Hash     string    `json:"hash"`
	MimeType string    `json:"mime_type"`
}

// CacheMetadata ç¼“å­˜å…ƒæ•°æ®
type CacheMetadata struct {
	APICallsCount    int          `json:"api_calls_count"`
	CacheHitRate     float64      `json:"cache_hit_rate"`
	LastSyncDuration string       `json:"last_sync_duration"` // å­˜å‚¨ä¸ºå­—ç¬¦ä¸²æ ¼å¼
	SyncHistory      []SyncRecord `json:"sync_history"`
}

// SyncRecord åŒæ­¥è®°å½•
type SyncRecord struct {
	Timestamp time.Time `json:"timestamp"`
	Duration  string    `json:"duration"` // å­˜å‚¨ä¸ºå­—ç¬¦ä¸²æ ¼å¼
	Added     int       `json:"added"`
	Modified  int       `json:"modified"`
	Deleted   int       `json:"deleted"`
	APICount  int       `json:"api_count"`
}

// SyncChanges åŒæ­¥å˜æ›´
type SyncChanges struct {
	Added         int
	Deleted       int
	Modified      int
	AddedFiles    []CachedFile
	DeletedFiles  []string
	ModifiedFiles []CachedFile
}

// NewSTRMPersistentCache åˆ›å»ºæ–°çš„æŒä¹…åŒ–ç¼“å­˜å®ä¾‹
func NewSTRMPersistentCache(backend, remotePath string, minFileSize int64, videoExts []string, urlFormat string) (*STRMPersistentCache, error) {
	// ç”Ÿæˆé…ç½®å“ˆå¸Œ
	configHash := generateConfigHash(backend, remotePath, minFileSize, videoExts, urlFormat)

	// è·å–ç¼“å­˜ç›®å½•
	cacheDir := getSTRMCacheDir()
	if err := os.MkdirAll(cacheDir, 0755); err != nil {
		return nil, fmt.Errorf("failed to create cache directory: %w", err)
	}

	// ç”Ÿæˆæ–‡ä»¶è·¯å¾„
	baseName := fmt.Sprintf("%s_%s_%s", backend, sanitizePath(remotePath), configHash[:8])
	cacheFile := filepath.Join(cacheDir, baseName+".json")
	metaFile := filepath.Join(cacheDir, "metadata", baseName+".meta")
	lockFile := filepath.Join(cacheDir, "locks", baseName+".lock")

	// åˆ›å»ºå­ç›®å½•
	os.MkdirAll(filepath.Dir(metaFile), 0755)
	os.MkdirAll(filepath.Dir(lockFile), 0755)

	spc := &STRMPersistentCache{
		backend:      backend,
		remotePath:   remotePath,
		configHash:   configHash,
		cacheDir:     cacheDir,
		cacheFile:    cacheFile,
		metaFile:     metaFile,
		lockFile:     lockFile,
		ttl:          5 * time.Minute, // é»˜è®¤5åˆ†é’Ÿ
		enabled:      true,
		syncInterval: 1 * time.Minute,
		maxCacheSize: 100 * 1024 * 1024, // 100MB
		compression:  true,
	}

	fs.Infof(nil, "ğŸ—ï¸ [CACHE] åˆå§‹åŒ–æŒä¹…åŒ–ç¼“å­˜: %s", baseName)
	return spc, nil
}

// getSTRMCacheDir è·å– STRM ç¼“å­˜ç›®å½•
func getSTRMCacheDir() string {
	cacheDir := config.GetCacheDir()
	return filepath.Join(cacheDir, "strm-cache")
}

// generateConfigHash ç”Ÿæˆé…ç½®å“ˆå¸Œ
func generateConfigHash(backend, remotePath string, minFileSize int64, videoExts []string, urlFormat string) string {
	data := fmt.Sprintf("%s:%s:%v:%v:%s",
		backend, remotePath, minFileSize, videoExts, urlFormat)
	hash := md5.Sum([]byte(data))
	return fmt.Sprintf("%x", hash)
}

// sanitizePath æ¸…ç†è·¯å¾„ç”¨äºæ–‡ä»¶å
func sanitizePath(path string) string {
	// æ›¿æ¢ä¸å®‰å…¨çš„å­—ç¬¦
	safe := strings.ReplaceAll(path, "/", "_")
	safe = strings.ReplaceAll(safe, "\\", "_")
	safe = strings.ReplaceAll(safe, ":", "_")
	safe = strings.ReplaceAll(safe, "*", "_")
	safe = strings.ReplaceAll(safe, "?", "_")
	safe = strings.ReplaceAll(safe, "\"", "_")
	safe = strings.ReplaceAll(safe, "<", "_")
	safe = strings.ReplaceAll(safe, ">", "_")
	safe = strings.ReplaceAll(safe, "|", "_")

	// é™åˆ¶é•¿åº¦
	if len(safe) > 50 {
		safe = safe[:50]
	}

	return safe
}

// LoadOrCreate åŠ è½½æˆ–åˆ›å»ºç¼“å­˜
func (spc *STRMPersistentCache) LoadOrCreate(ctx context.Context, fsys fs.Fs) (*CacheData, error) {
	if !spc.enabled {
		return spc.createFreshCache(ctx, fsys)
	}

	// è·å–æ–‡ä»¶é”
	if err := spc.acquireLock(); err != nil {
		fs.Logf(nil, "âš ï¸ [CACHE] è·å–é”å¤±è´¥ï¼Œä½¿ç”¨æ— ç¼“å­˜æ¨¡å¼: %v", err)
		return spc.createFreshCache(ctx, fsys)
	}
	defer spc.releaseLock()

	// æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if !spc.cacheFileExists() {
		fs.Infof(nil, "ğŸ†• [CACHE] é¦–æ¬¡å¯åŠ¨ï¼Œåˆ›å»ºæ–°ç¼“å­˜")
		return spc.createFreshCache(ctx, fsys)
	}

	// åŠ è½½ç°æœ‰ç¼“å­˜
	cacheData, err := spc.loadFromDisk()
	if err != nil {
		fs.Logf(nil, "âš ï¸ [CACHE] åŠ è½½å¤±è´¥ï¼Œåˆ›å»ºæ–°ç¼“å­˜: %v", err)
		return spc.createFreshCache(ctx, fsys)
	}

	// éªŒè¯ç¼“å­˜æœ‰æ•ˆæ€§
	if !spc.validateCache(cacheData) {
		fs.Infof(nil, "âŒ [CACHE] ç¼“å­˜æ— æ•ˆï¼Œåˆ›å»ºæ–°ç¼“å­˜")
		return spc.createFreshCache(ctx, fsys)
	}

	// åˆ†å±‚ç¼“å­˜ç­–ç•¥ï¼šæŒä¹…åŒ–ç¼“å­˜æ°¸ä¸è¿‡æœŸï¼Œä½†æœ‰å®‰å…¨é™åˆ¶
	cacheAge := time.Since(cacheData.CreatedAt)
	maxSafeAge := 7 * 24 * time.Hour // æœ€å¤§å®‰å…¨å¹´é¾„ï¼š7å¤©

	if cacheAge > maxSafeAge {
		fs.Logf(nil, "âš ï¸ [CACHE] ç¼“å­˜å¹´é¾„è¿‡å¤§ (%v > %v)ï¼Œå»ºè®®æ‰‹åŠ¨åˆ·æ–°", cacheAge, maxSafeAge)
	}

	fs.Infof(nil, "â™¾ï¸ [CACHE] ä½¿ç”¨æŒä¹…åŒ–ç¼“å­˜ (%d ä¸ªæ–‡ä»¶, åˆ›å»ºæ—¶é—´: %v, å¹´é¾„: %v)",
		cacheData.FileCount, cacheData.CreatedAt.Format("15:04:05"), cacheAge)
	fs.Infof(nil, "ğŸ“‚ [CACHE] æŒ‰éœ€åŒæ­¥æ¨¡å¼ï¼šè®¿é—®ç›®å½•æ—¶æ‰åŒæ­¥æ–°æ–‡ä»¶")

	return cacheData, nil
}

// cacheFileExists æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
func (spc *STRMPersistentCache) cacheFileExists() bool {
	_, err := os.Stat(spc.cacheFile)
	return err == nil
}

// validateCache éªŒè¯ç¼“å­˜æœ‰æ•ˆæ€§
func (spc *STRMPersistentCache) validateCache(cacheData *CacheData) bool {
	// æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
	if cacheData.Version != "1.0" {
		return false
	}

	// æ£€æŸ¥åç«¯åŒ¹é…
	if cacheData.Backend != spc.backend {
		return false
	}

	// æ£€æŸ¥è·¯å¾„åŒ¹é…
	if cacheData.RemotePath != spc.remotePath {
		return false
	}

	// æ£€æŸ¥é…ç½®å“ˆå¸Œ
	if cacheData.ConfigHash != spc.configHash {
		return false
	}

	return true
}

// acquireLock è·å–æ–‡ä»¶é”
func (spc *STRMPersistentCache) acquireLock() error {
	// ç®€å•çš„æ–‡ä»¶é”å®ç°
	lockFile, err := os.OpenFile(spc.lockFile, os.O_CREATE|os.O_EXCL|os.O_WRONLY, 0644)
	if err != nil {
		return fmt.Errorf("failed to acquire lock: %w", err)
	}

	// å†™å…¥è¿›ç¨‹ä¿¡æ¯
	fmt.Fprintf(lockFile, "%d\n%s\n", os.Getpid(), time.Now().Format(time.RFC3339))
	lockFile.Close()

	return nil
}

// releaseLock é‡Šæ”¾æ–‡ä»¶é”
func (spc *STRMPersistentCache) releaseLock() {
	os.Remove(spc.lockFile)
}

// createCachedFile ä» fs.Object åˆ›å»º CachedFile
func (spc *STRMPersistentCache) createCachedFile(obj fs.Object) CachedFile {
	cached := CachedFile{
		Name:    filepath.Base(obj.Remote()),
		Size:    obj.Size(),
		ModTime: obj.ModTime(context.Background()),
	}

	// è·å–æ–‡ä»¶IDå’ŒPickCode (æ ¹æ®åç«¯ç±»å‹)
	switch spc.backend {
	case "123":
		if obj123, ok := obj.(interface{ GetID() string }); ok {
			cached.FileID = obj123.GetID()
		}
	case "115":
		if obj115, ok := obj.(interface{ GetPickCode() string }); ok {
			cached.PickCode = obj115.GetPickCode()
		}
	}

	// è·å–å“ˆå¸Œå€¼
	if hashValue, err := obj.Hash(context.Background(), hash.SHA1); err == nil && hashValue != "" {
		cached.Hash = "sha1:" + hashValue
	}

	return cached
}

// SetEnabled å¯ç”¨æˆ–ç¦ç”¨æŒä¹…åŒ–ç¼“å­˜
func (spc *STRMPersistentCache) SetEnabled(enabled bool) {
	spc.mu.Lock()
	defer spc.mu.Unlock()
	spc.enabled = enabled
}

// SetTTL è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´
func (spc *STRMPersistentCache) SetTTL(ttl time.Duration) {
	spc.mu.Lock()
	defer spc.mu.Unlock()
	spc.ttl = ttl
}

// createFreshCache åˆ›å»ºæ–°çš„ç¼“å­˜
func (spc *STRMPersistentCache) createFreshCache(ctx context.Context, fsys fs.Fs) (*CacheData, error) {
	startTime := time.Now()
	fs.Infof(nil, "ğŸ†• [CACHE] å¼€å§‹åˆ›å»ºæ–°ç¼“å­˜...")

	// è·å–è¿œç¨‹æ–‡ä»¶åˆ—è¡¨
	remoteFiles, err := spc.fetchRemoteFiles(ctx, fsys)
	if err != nil {
		return nil, fmt.Errorf("è·å–è¿œç¨‹æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// åˆ›å»ºç¼“å­˜æ•°æ®
	now := time.Now()
	cacheData := &CacheData{
		Version:     "1.0",
		Backend:     spc.backend,
		RemotePath:  spc.remotePath,
		ConfigHash:  spc.configHash,
		CreatedAt:   now,
		UpdatedAt:   now,
		ExpiresAt:   now.Add(spc.ttl),
		FileCount:   len(remoteFiles),
		Directories: spc.organizeFilesByDirectory(remoteFiles),
		Metadata: CacheMetadata{
			APICallsCount:    1, // ä¸€æ¬¡ List è°ƒç”¨
			CacheHitRate:     0.0,
			LastSyncDuration: time.Since(startTime).String(),
			SyncHistory: []SyncRecord{
				{
					Timestamp: now,
					Duration:  time.Since(startTime).String(),
					Added:     len(remoteFiles),
					Modified:  0,
					Deleted:   0,
					APICount:  1,
				},
			},
		},
	}

	// è®¡ç®—æ€»å¤§å°
	for _, dir := range cacheData.Directories {
		cacheData.TotalSize += dir.TotalSize
	}

	// ä¿å­˜åˆ°ç£ç›˜
	if err := spc.saveToDisk(cacheData); err != nil {
		return nil, fmt.Errorf("ä¿å­˜ç¼“å­˜å¤±è´¥: %w", err)
	}

	duration := time.Since(startTime)
	fs.Infof(nil, "âœ… [CACHE] æ–°ç¼“å­˜åˆ›å»ºå®Œæˆ: %d ä¸ªæ–‡ä»¶, è€—æ—¶ %v",
		cacheData.FileCount, duration)

	return cacheData, nil
}

// fetchRemoteFiles è·å–è¿œç¨‹æ–‡ä»¶åˆ—è¡¨ï¼ˆæ™ºèƒ½é™åˆ¶æ‰«æèŒƒå›´ï¼‰
func (spc *STRMPersistentCache) fetchRemoteFiles(ctx context.Context, fsys fs.Fs) ([]fs.Object, error) {
	// ğŸ›¡ï¸ æ™ºèƒ½QPSä¿æŠ¤ï¼šåªæ‰«ææ ¹ç›®å½•ï¼Œé¿å…æ·±åº¦é€’å½’
	fs.Infof(nil, "ğŸ” [CACHE] æ™ºèƒ½æ‰«ææ¨¡å¼ï¼šä»…æ‰«ææ ¹ç›®å½•ï¼Œé¿å…æ·±åº¦é€’å½’")

	var files []fs.Object

	// åªåˆ—å‡ºæ ¹ç›®å½•ï¼Œä¸é€’å½’å­ç›®å½•
	entries, err := fsys.List(ctx, "")
	if err != nil {
		return nil, fmt.Errorf("åˆ—å‡ºæ ¹ç›®å½•å¤±è´¥: %w", err)
	}

	// åªå¤„ç†æ ¹ç›®å½•ä¸­çš„è§†é¢‘æ–‡ä»¶
	for _, entry := range entries {
		if obj, ok := entry.(fs.Object); ok {
			if spc.isVideoFile(obj) {
				files = append(files, obj)
			}
		}
	}

	fs.Infof(nil, "ğŸ“ [CACHE] æ ¹ç›®å½•æ‰«æå®Œæˆ: %d ä¸ªè§†é¢‘æ–‡ä»¶", len(files))
	return files, nil
}

// isVideoFile æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
func (spc *STRMPersistentCache) isVideoFile(obj fs.Object) bool {
	name := obj.Remote()
	size := obj.Size()

	// æ£€æŸ¥æ–‡ä»¶å¤§å° (è¿™é‡Œéœ€è¦ä»é…ç½®è·å–ï¼Œæš‚æ—¶ç¡¬ç¼–ç )
	minSize := int64(100 * 1024 * 1024) // 100MB
	if size < minSize {
		return false
	}

	// æ£€æŸ¥æ‰©å±•å
	ext := strings.ToLower(filepath.Ext(name))
	videoExts := []string{".iso", ".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv", ".webm", ".m4v", ".3gp", ".ts", ".m2ts"}

	for _, videoExt := range videoExts {
		if ext == videoExt {
			return true
		}
	}

	return false
}

// organizeFilesByDirectory æŒ‰ç›®å½•ç»„ç»‡æ–‡ä»¶
func (spc *STRMPersistentCache) organizeFilesByDirectory(files []fs.Object) []CachedDirectory {
	dirMap := make(map[string]*CachedDirectory)

	for _, obj := range files {
		dirPath := filepath.Dir(obj.Remote())
		if dirPath == "." {
			dirPath = ""
		}

		// è·å–æˆ–åˆ›å»ºç›®å½•æ¡ç›®
		dir, exists := dirMap[dirPath]
		if !exists {
			dir = &CachedDirectory{
				Path:      dirPath,
				ModTime:   obj.ModTime(context.Background()),
				FileCount: 0,
				TotalSize: 0,
				Files:     []CachedFile{},
			}
			dirMap[dirPath] = dir
		}

		// æ·»åŠ æ–‡ä»¶
		cachedFile := spc.createCachedFile(obj)
		dir.Files = append(dir.Files, cachedFile)
		dir.FileCount++
		dir.TotalSize += cachedFile.Size

		// æ›´æ–°ç›®å½•ä¿®æ”¹æ—¶é—´ä¸ºæœ€æ–°æ–‡ä»¶çš„æ—¶é—´
		if cachedFile.ModTime.After(dir.ModTime) {
			dir.ModTime = cachedFile.ModTime
		}
	}

	// è½¬æ¢ä¸ºåˆ‡ç‰‡
	var directories []CachedDirectory
	for _, dir := range dirMap {
		directories = append(directories, *dir)
	}

	return directories
}

// GetStats è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (spc *STRMPersistentCache) GetStats() map[string]interface{} {
	spc.mu.RLock()
	defer spc.mu.RUnlock()

	stats := map[string]interface{}{
		"enabled":       spc.enabled,
		"backend":       spc.backend,
		"remote_path":   spc.remotePath,
		"cache_file":    spc.cacheFile,
		"ttl":           spc.ttl.String(),
		"last_sync":     spc.lastSync.Format(time.RFC3339),
		"sync_interval": spc.syncInterval.String(),
	}

	// æ·»åŠ æ–‡ä»¶å¤§å°ä¿¡æ¯
	if info, err := os.Stat(spc.cacheFile); err == nil {
		stats["cache_size"] = info.Size()
		stats["cache_mod_time"] = info.ModTime().Format(time.RFC3339)
	}

	return stats
}

// loadFromDisk ä»ç£ç›˜åŠ è½½ç¼“å­˜æ•°æ®
func (spc *STRMPersistentCache) loadFromDisk() (*CacheData, error) {
	data, err := os.ReadFile(spc.cacheFile)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: %w", err)
	}

	var cacheData CacheData
	if err := json.Unmarshal(data, &cacheData); err != nil {
		return nil, fmt.Errorf("è§£æç¼“å­˜æ•°æ®å¤±è´¥: %w", err)
	}

	return &cacheData, nil
}

// saveToDisk ä¿å­˜ç¼“å­˜æ•°æ®åˆ°ç£ç›˜
func (spc *STRMPersistentCache) saveToDisk(cacheData *CacheData) error {
	// æ›´æ–°æ—¶é—´æˆ³
	cacheData.UpdatedAt = time.Now()

	// åºåˆ—åŒ–ä¸º JSON
	data, err := json.MarshalIndent(cacheData, "", "  ")
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–ç¼“å­˜æ•°æ®å¤±è´¥: %w", err)
	}

	// å†™å…¥ä¸´æ—¶æ–‡ä»¶
	tempFile := spc.cacheFile + ".tmp"
	if err := os.WriteFile(tempFile, data, 0644); err != nil {
		return fmt.Errorf("å†™å…¥ä¸´æ—¶æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// åŸå­æ€§é‡å‘½å
	if err := os.Rename(tempFile, spc.cacheFile); err != nil {
		os.Remove(tempFile) // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
		return fmt.Errorf("é‡å‘½åç¼“å­˜æ–‡ä»¶å¤±è´¥: %w", err)
	}

	fs.Debugf(nil, "ğŸ’¾ [CACHE] ç¼“å­˜å·²ä¿å­˜: %d ä¸ªæ–‡ä»¶, å¤§å°: %d å­—èŠ‚",
		cacheData.FileCount, len(data))
	return nil
}

// incrementalSync æ‰§è¡Œå¢é‡åŒæ­¥ï¼ˆæ™ºèƒ½é™åˆ¶æ‰«æèŒƒå›´ï¼‰
func (spc *STRMPersistentCache) incrementalSync(ctx context.Context, fsys fs.Fs, oldCache *CacheData) (*CacheData, error) {
	startTime := time.Now()
	fs.Infof(nil, "ğŸ”„ [SYNC] å¼€å§‹æ™ºèƒ½å¢é‡åŒæ­¥ï¼ˆä»…æ ¹ç›®å½•ï¼‰...")

	// ğŸ›¡ï¸ æ™ºèƒ½QPSä¿æŠ¤ï¼šåªè·å–æ ¹ç›®å½•æ–‡ä»¶ï¼Œé¿å…æ·±åº¦é€’å½’
	remoteFiles, err := spc.fetchRemoteFiles(ctx, fsys)
	if err != nil {
		return nil, fmt.Errorf("è·å–è¿œç¨‹æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// æ£€æµ‹å˜æ›´
	changes := spc.detectChanges(oldCache, remoteFiles)

	// åº”ç”¨å˜æ›´
	newCache := spc.applyChanges(oldCache, changes)
	newCache.UpdatedAt = time.Now()
	newCache.ExpiresAt = time.Now().Add(spc.ttl)

	// æ›´æ–°å…ƒæ•°æ®
	syncRecord := SyncRecord{
		Timestamp: time.Now(),
		Duration:  time.Since(startTime).String(),
		Added:     changes.Added,
		Modified:  changes.Modified,
		Deleted:   changes.Deleted,
		APICount:  1, // ä¸€æ¬¡æ ¹ç›®å½•Listè°ƒç”¨
	}

	newCache.Metadata.SyncHistory = append(newCache.Metadata.SyncHistory, syncRecord)
	if len(newCache.Metadata.SyncHistory) > 10 {
		newCache.Metadata.SyncHistory = newCache.Metadata.SyncHistory[1:]
	}

	newCache.Metadata.LastSyncDuration = syncRecord.Duration
	newCache.Metadata.APICallsCount += syncRecord.APICount

	// ä¿å­˜æ–°ç¼“å­˜
	if err := spc.saveToDisk(newCache); err != nil {
		return nil, fmt.Errorf("ä¿å­˜ç¼“å­˜å¤±è´¥: %w", err)
	}

	// æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
	spc.updateLastSyncTime()

	duration := time.Since(startTime)
	fs.Infof(nil, "âœ… [SYNC] æ™ºèƒ½åŒæ­¥å®Œæˆ: +%d -%d ~%d (è€—æ—¶ %v, ä»…æ ¹ç›®å½•)",
		changes.Added, changes.Deleted, changes.Modified, duration)

	return newCache, nil
}

// detectChanges æ£€æµ‹æ–‡ä»¶å˜æ›´
func (spc *STRMPersistentCache) detectChanges(oldCache *CacheData, remoteFiles []fs.Object) *SyncChanges {
	changes := &SyncChanges{}

	// åˆ›å»ºæœ¬åœ°æ–‡ä»¶æ˜ å°„ (path -> CachedFile)
	localFiles := make(map[string]CachedFile)
	for _, dir := range oldCache.Directories {
		for _, file := range dir.Files {
			fullPath := filepath.Join(dir.Path, file.Name)
			localFiles[fullPath] = file
		}
	}

	// åˆ›å»ºè¿œç¨‹æ–‡ä»¶æ˜ å°„
	remoteFileMap := make(map[string]fs.Object)
	for _, obj := range remoteFiles {
		remoteFileMap[obj.Remote()] = obj
	}

	// æ£€æµ‹æ–°å¢å’Œä¿®æ”¹çš„æ–‡ä»¶
	for remotePath, remoteObj := range remoteFileMap {
		if localFile, exists := localFiles[remotePath]; exists {
			// æ–‡ä»¶å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦ä¿®æ”¹
			if spc.isFileModified(localFile, remoteObj) {
				changes.ModifiedFiles = append(changes.ModifiedFiles,
					spc.createCachedFile(remoteObj))
				changes.Modified++
			}
		} else {
			// æ–°æ–‡ä»¶
			changes.AddedFiles = append(changes.AddedFiles,
				spc.createCachedFile(remoteObj))
			changes.Added++
		}
	}

	// å®‰å…¨çš„åˆ é™¤æ£€æµ‹ï¼šåªæœ‰åœ¨æœ‰è¿œç¨‹æ–‡ä»¶æ•°æ®æ—¶æ‰æ£€æµ‹åˆ é™¤
	if len(remoteFiles) > 0 {
		// æœ‰è¿œç¨‹æ–‡ä»¶æ•°æ®ï¼Œå¯ä»¥å®‰å…¨åœ°æ£€æµ‹åˆ é™¤
		for localPath := range localFiles {
			if _, exists := remoteFileMap[localPath]; !exists {
				changes.DeletedFiles = append(changes.DeletedFiles, localPath)
				changes.Deleted++
				fs.Debugf(nil, "ğŸ—‘ï¸ [DETECT] æ£€æµ‹åˆ°åˆ é™¤æ–‡ä»¶: %s", localPath)
			}
		}
	} else {
		// æ²¡æœ‰è¿œç¨‹æ–‡ä»¶æ•°æ®ï¼Œå¯èƒ½æ˜¯APIè°ƒç”¨å¤±è´¥ï¼Œä¸æ‰§è¡Œåˆ é™¤æ£€æµ‹é¿å…è¯¯åˆ 
		fs.Debugf(nil, "âš ï¸ [DETECT] æ²¡æœ‰è¿œç¨‹æ–‡ä»¶æ•°æ®ï¼Œè·³è¿‡åˆ é™¤æ£€æµ‹ä»¥é¿å…è¯¯åˆ ")
	}

	return changes
}

// isFileModified æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«ä¿®æ”¹
func (spc *STRMPersistentCache) isFileModified(local CachedFile, remote fs.Object) bool {
	// æ¯”è¾ƒæ–‡ä»¶å¤§å°
	if local.Size != remote.Size() {
		return true
	}

	// æ¯”è¾ƒä¿®æ”¹æ—¶é—´
	if !local.ModTime.Equal(remote.ModTime(context.Background())) {
		return true
	}

	// æ¯”è¾ƒå“ˆå¸Œå€¼ (å¦‚æœå¯ç”¨)
	if hashValue, err := remote.Hash(context.Background(), hash.SHA1); err == nil && hashValue != "" {
		expectedHash := "sha1:" + hashValue
		if local.Hash != expectedHash {
			return true
		}
	}

	return false
}

// applyChanges åº”ç”¨å¢é‡å˜æ›´åˆ°ç¼“å­˜
func (spc *STRMPersistentCache) applyChanges(oldCache *CacheData, changes *SyncChanges) *CacheData {
	// åˆ›å»ºæ–°çš„ç¼“å­˜æ•°æ®ï¼Œå¤åˆ¶åŸæœ‰æ•°æ®
	newCache := &CacheData{
		Version:     oldCache.Version,
		Backend:     oldCache.Backend,
		RemotePath:  oldCache.RemotePath,
		ConfigHash:  oldCache.ConfigHash,
		CreatedAt:   oldCache.CreatedAt,
		Metadata:    oldCache.Metadata,
		Directories: make([]CachedDirectory, len(oldCache.Directories)),
	}

	// å¤åˆ¶åŸæœ‰ç›®å½•ç»“æ„
	copy(newCache.Directories, oldCache.Directories)

	// åº”ç”¨å¢é‡å˜æ›´
	fs.Infof(nil, "ğŸ”„ [APPLY] åº”ç”¨å¢é‡å˜æ›´: +%d ~%d -%d",
		changes.Added, changes.Modified, changes.Deleted)

	// 1. æ·»åŠ æ–°æ–‡ä»¶
	for _, addedFile := range changes.AddedFiles {
		spc.addFileToDirectories(&newCache.Directories, addedFile)
	}

	// 2. æ›´æ–°ä¿®æ”¹çš„æ–‡ä»¶
	for _, modifiedFile := range changes.ModifiedFiles {
		spc.updateFileInDirectories(&newCache.Directories, modifiedFile)
	}

	// 3. åˆ é™¤å·²åˆ é™¤çš„æ–‡ä»¶
	for _, deletedPath := range changes.DeletedFiles {
		spc.removeFileFromDirectories(&newCache.Directories, deletedPath)
	}

	// é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
	newCache.FileCount = 0
	newCache.TotalSize = 0
	for _, dir := range newCache.Directories {
		newCache.FileCount += dir.FileCount
		newCache.TotalSize += dir.TotalSize
	}

	fs.Infof(nil, "âœ… [APPLY] å¢é‡å˜æ›´åº”ç”¨å®Œæˆ: %d ä¸ªæ–‡ä»¶, æ€»å¤§å° %d",
		newCache.FileCount, newCache.TotalSize)

	return newCache
}

// shouldPerformBackgroundSync åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œåå°å¢é‡åŒæ­¥
func (spc *STRMPersistentCache) shouldPerformBackgroundSync(cacheData *CacheData) bool {
	spc.mu.RLock()
	defer spc.mu.RUnlock()

	// å¦‚æœç¼“å­˜è¢«ç¦ç”¨ï¼Œä¸æ‰§è¡ŒåŒæ­¥
	if !spc.enabled {
		return false
	}

	// æ£€æŸ¥è·ç¦»ä¸Šæ¬¡åŒæ­¥çš„æ—¶é—´
	timeSinceLastSync := time.Since(spc.lastSync)

	// å¦‚æœè·ç¦»ä¸Šæ¬¡åŒæ­¥è¶…è¿‡åŒæ­¥é—´éš”ï¼Œæ‰§è¡ŒåŒæ­¥
	if timeSinceLastSync > spc.syncInterval {
		fs.Debugf(nil, "ğŸ• [CACHE] è·ç¦»ä¸Šæ¬¡åŒæ­¥ %vï¼Œè¶…è¿‡é—´éš” %vï¼Œéœ€è¦åŒæ­¥",
			timeSinceLastSync, spc.syncInterval)
		return true
	}

	// æ£€æŸ¥ç¼“å­˜å¹´é¾„ï¼Œå¦‚æœç¼“å­˜å¾ˆæ—§ï¼Œä¹Ÿæ‰§è¡ŒåŒæ­¥
	cacheAge := time.Since(cacheData.UpdatedAt)
	maxCacheAge := 24 * time.Hour // æœ€å¤§ç¼“å­˜å¹´é¾„24å°æ—¶

	if cacheAge > maxCacheAge {
		fs.Debugf(nil, "ğŸ“… [CACHE] ç¼“å­˜å¹´é¾„ %v è¶…è¿‡æœ€å¤§å¹´é¾„ %vï¼Œéœ€è¦åŒæ­¥",
			cacheAge, maxCacheAge)
		return true
	}

	fs.Debugf(nil, "â­ï¸ [CACHE] æ— éœ€åŒæ­¥ï¼šè·ç¦»ä¸Šæ¬¡åŒæ­¥ %vï¼Œç¼“å­˜å¹´é¾„ %v",
		timeSinceLastSync, cacheAge)
	return false
}

// updateLastSyncTime æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
func (spc *STRMPersistentCache) updateLastSyncTime() {
	spc.mu.Lock()
	defer spc.mu.Unlock()
	spc.lastSync = time.Now()
}

// OnDemandSync æŒ‰éœ€åŒæ­¥ï¼šè®¿é—®ç›®å½•æ—¶è§¦å‘åŒæ­¥ï¼ˆå¸¦é˜²é‡å¤æœºåˆ¶ï¼‰
func (spc *STRMPersistentCache) OnDemandSync(ctx context.Context, fsys fs.Fs, dirPath string) error {
	fs.Infof(nil, "ğŸ¯ [CACHE] æŒ‰éœ€åŒæ­¥å¼€å§‹ - å¤„ç†ç›®å½•: %s", dirPath)

	if !spc.enabled {
		fs.Infof(nil, "â­ï¸ [CACHE] æŒä¹…åŒ–ç¼“å­˜åŠŸèƒ½æœªå¯ç”¨ - è·³è¿‡åŒæ­¥æ“ä½œ")
		return nil
	}

	spc.mu.Lock()
	defer spc.mu.Unlock()

	// æ™ºèƒ½è·³è¿‡æœºåˆ¶ï¼šå¤šé‡æ£€æŸ¥å‡å°‘ä¸å¿…è¦çš„APIè°ƒç”¨
	if !spc.shouldSyncDirectory(dirPath) {
		fs.Infof(nil, "âœ… [CACHE] ç¼“å­˜å‘½ä¸­ - ç›®å½• %s ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œè·³è¿‡åŒæ­¥", dirPath)
		return nil
	}

	timeSinceLastSync := time.Since(spc.lastSync)
	minSyncInterval := spc.getDirectorySyncInterval(dirPath)

	fs.Infof(nil, "ğŸ”„ [CACHE] ç¼“å­˜å¤±æ•ˆï¼Œå¼€å§‹åŒæ­¥ - %s (ä¸Šæ¬¡åŒæ­¥: %vå‰, ç¼“å­˜é—´éš”: %v)",
		dirPath, timeSinceLastSync, minSyncInterval)

	// åŠ è½½å½“å‰ç¼“å­˜
	cacheData, err := spc.loadFromDisk()
	if err != nil {
		fs.Errorf(nil, "âŒ [ON-DEMAND] åŠ è½½ç¼“å­˜å¤±è´¥: %v", err)
		return err
	}

	// æ‰§è¡Œç²¾ç¡®çš„ç›®å½•åŒæ­¥ï¼Œè€Œä¸æ˜¯æ€»æ˜¯æ‰«ææ ¹ç›®å½•
	newCache, err := spc.incrementalSyncDirectory(ctx, fsys, cacheData, dirPath)
	if err != nil {
		fs.Errorf(nil, "âŒ [ON-DEMAND] åŒæ­¥å¤±è´¥: %v", err)
		return err
	}

	// ä¿å­˜æ›´æ–°åçš„ç¼“å­˜
	if err := spc.saveToDisk(newCache); err != nil {
		fs.Errorf(nil, "âŒ [ON-DEMAND] ä¿å­˜ç¼“å­˜å¤±è´¥: %v", err)
		return err
	}

	// æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
	spc.lastSync = time.Now()

	fs.Infof(nil, "âœ… [SYNC] ç›®å½•åŒæ­¥æˆåŠŸå®Œæˆ - %s (æ•°æ®å·²æ›´æ–°)", dirPath)
	return nil
}

// addFileToDirectories çœŸæ­£æ·»åŠ æ–‡ä»¶åˆ°ç›®å½•åˆ—è¡¨
func (spc *STRMPersistentCache) addFileToDirectories(directories *[]CachedDirectory, file CachedFile) {
	// æŸ¥æ‰¾æˆ–åˆ›å»ºæ ¹ç›®å½•
	var rootDir *CachedDirectory
	for i := range *directories {
		if (*directories)[i].Path == "" {
			rootDir = &(*directories)[i]
			break
		}
	}

	if rootDir == nil {
		// åˆ›å»ºæ ¹ç›®å½•
		*directories = append(*directories, CachedDirectory{
			Path:  "",
			Files: []CachedFile{},
		})
		rootDir = &(*directories)[len(*directories)-1]
	}

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
	for i, existingFile := range rootDir.Files {
		if existingFile.Name == file.Name {
			// æ›´æ–°ç°æœ‰æ–‡ä»¶
			rootDir.Files[i] = file
			fs.Debugf(nil, "ğŸ“ [ADD] æ›´æ–°ç°æœ‰æ–‡ä»¶: %s", file.Name)
			return
		}
	}

	// æ·»åŠ æ–°æ–‡ä»¶
	rootDir.Files = append(rootDir.Files, file)
	rootDir.FileCount++
	rootDir.TotalSize += file.Size
	fs.Debugf(nil, "ğŸ“ [ADD] æ·»åŠ æ–°æ–‡ä»¶: %s (å¤§å°: %d)", file.Name, file.Size)
}

// updateFileInDirectories çœŸæ­£æ›´æ–°ç›®å½•åˆ—è¡¨ä¸­çš„æ–‡ä»¶
func (spc *STRMPersistentCache) updateFileInDirectories(directories *[]CachedDirectory, file CachedFile) {
	// å…ˆåˆ é™¤æ—§æ–‡ä»¶ï¼Œå†æ·»åŠ æ–°æ–‡ä»¶
	spc.removeFileFromDirectories(directories, file.Name)
	spc.addFileToDirectories(directories, file)
	fs.Debugf(nil, "ğŸ“ [UPDATE] æ›´æ–°æ–‡ä»¶: %s", file.Name)
}

// removeFileFromDirectories ä»ç›®å½•åˆ—è¡¨ä¸­åˆ é™¤æ–‡ä»¶
func (spc *STRMPersistentCache) removeFileFromDirectories(directories *[]CachedDirectory, filePath string) {
	fileName := filepath.Base(filePath)
	fs.Debugf(nil, "ğŸ—‘ï¸ [DELETE] åˆ é™¤æ–‡ä»¶: %s", fileName)

	// éå†æ‰€æœ‰ç›®å½•ï¼Œæ‰¾åˆ°å¹¶åˆ é™¤æ–‡ä»¶
	for i := range *directories {
		dir := &(*directories)[i]
		for j, file := range dir.Files {
			if file.Name == fileName {
				// åˆ é™¤æ–‡ä»¶
				dir.Files = append(dir.Files[:j], dir.Files[j+1:]...)
				dir.FileCount--
				dir.TotalSize -= file.Size
				fs.Debugf(nil, "âœ… [DELETE] å·²åˆ é™¤æ–‡ä»¶: %s", fileName)
				return
			}
		}
	}
}

// getDirectorySyncInterval æ ¹æ®ç›®å½•ç±»å‹è¿”å›æ™ºèƒ½ç¼“å­˜é—´éš”
func (spc *STRMPersistentCache) getDirectorySyncInterval(dirPath string) time.Duration {
	// æ ¹æ®ç›®å½•ç‰¹æ€§è®¾ç½®ä¸åŒçš„ç¼“å­˜æ—¶é—´ï¼Œå¤§å¹…å‡å°‘APIè°ƒç”¨
	switch {
	case dirPath == "" || dirPath == "/":
		// æ ¹ç›®å½•ï¼šå˜åŒ–è¾ƒå°‘ï¼Œè®¾ç½®é•¿ç¼“å­˜æ—¶é—´
		return 4 * time.Hour
	case strings.Contains(strings.ToLower(dirPath), "download"):
		// ä¸‹è½½ç›®å½•ï¼šå¯èƒ½æœ‰æ–°æ–‡ä»¶ï¼Œä½†ä¸éœ€è¦å¤ªé¢‘ç¹æ£€æŸ¥
		return 1 * time.Hour
	case strings.Contains(strings.ToLower(dirPath), "temp") || strings.Contains(strings.ToLower(dirPath), "tmp"):
		// ä¸´æ—¶ç›®å½•ï¼šå˜åŒ–é¢‘ç¹ï¼Œä½†ç”¨æˆ·è®¿é—®å°‘
		return 30 * time.Minute
	case strings.Count(dirPath, "/") > 2:
		// æ·±å±‚ç›®å½•ï¼šå¾ˆå°‘å˜åŒ–ï¼Œè®¾ç½®æœ€é•¿ç¼“å­˜æ—¶é—´
		return 8 * time.Hour
	default:
		// æ™®é€šç›®å½•ï¼šä¸­ç­‰ç¼“å­˜æ—¶é—´
		return 2 * time.Hour
	}
}

// incrementalSyncDirectory ç²¾ç¡®åŒæ­¥æŒ‡å®šç›®å½•ï¼Œå‡å°‘ä¸å¿…è¦çš„APIè°ƒç”¨
func (spc *STRMPersistentCache) incrementalSyncDirectory(ctx context.Context, fsys fs.Fs, oldCache *CacheData, targetDir string) (*CacheData, error) {
	startTime := time.Now()
	fs.Debugf(nil, "ğŸ¯ [SYNC] å¼€å§‹ç²¾ç¡®åŒæ­¥ - ç›®æ ‡ç›®å½•: %s (æ£€æŸ¥æ–‡ä»¶å˜æ›´)", targetDir)

	// ç²¾ç¡®è·å–æŒ‡å®šç›®å½•çš„æ–‡ä»¶ï¼Œè€Œä¸æ˜¯æ€»æ˜¯æ‰«ææ ¹ç›®å½•
	remoteFiles, err := spc.fetchRemoteFilesFromDirectory(ctx, fsys, targetDir)
	if err != nil {
		return nil, fmt.Errorf("è·å–ç›®å½• %s æ–‡ä»¶å¤±è´¥: %w", targetDir, err)
	}

	// æ£€æµ‹å˜æ›´
	changes := spc.detectChanges(oldCache, remoteFiles)

	// åº”ç”¨å˜æ›´
	newCache := spc.applyChanges(oldCache, changes)
	newCache.UpdatedAt = time.Now()

	// æ›´æ–°å…ƒæ•°æ®
	syncRecord := SyncRecord{
		Timestamp: time.Now(),
		Duration:  time.Since(startTime).String(),
		Added:     changes.Added,
		Modified:  changes.Modified,
		Deleted:   changes.Deleted,
		APICount:  1, // ä¸€æ¬¡ç²¾ç¡®ç›®å½•è°ƒç”¨
	}

	newCache.Metadata.SyncHistory = append(newCache.Metadata.SyncHistory, syncRecord)
	if len(newCache.Metadata.SyncHistory) > 10 {
		newCache.Metadata.SyncHistory = newCache.Metadata.SyncHistory[1:]
	}

	newCache.Metadata.LastSyncDuration = syncRecord.Duration
	newCache.Metadata.APICallsCount += syncRecord.APICount

	// ä¿å­˜æ–°ç¼“å­˜
	if err := spc.saveToDisk(newCache); err != nil {
		return nil, fmt.Errorf("ä¿å­˜ç¼“å­˜å¤±è´¥: %w", err)
	}

	// æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
	spc.updateLastSyncTime()

	duration := time.Since(startTime)
	fs.Infof(nil, "âœ… [SYNC] ç²¾ç¡®åŒæ­¥å®Œæˆ %s: +%d -%d ~%d (è€—æ—¶ %v)",
		targetDir, changes.Added, changes.Deleted, changes.Modified, duration)

	return newCache, nil
}

// fetchRemoteFilesFromDirectory ç²¾ç¡®è·å–æŒ‡å®šç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
func (spc *STRMPersistentCache) fetchRemoteFilesFromDirectory(ctx context.Context, fsys fs.Fs, targetDir string) ([]fs.Object, error) {
	fs.Infof(nil, "ğŸ” [CACHE] ç²¾ç¡®æ‰«æå¼€å§‹ - ç›®å½•: %s (æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶)", targetDir)

	var files []fs.Object

	// ç²¾ç¡®åˆ—å‡ºæŒ‡å®šç›®å½•ï¼Œè€Œä¸æ˜¯æ€»æ˜¯æ‰«ææ ¹ç›®å½•
	entries, err := fsys.List(ctx, targetDir)
	if err != nil {
		return nil, fmt.Errorf("åˆ—å‡ºç›®å½• %s å¤±è´¥: %w", targetDir, err)
	}

	// åªå¤„ç†è¯¥ç›®å½•ä¸­çš„è§†é¢‘æ–‡ä»¶
	for _, entry := range entries {
		if obj, ok := entry.(fs.Object); ok {
			if spc.isVideoFile(obj) {
				files = append(files, obj)
			}
		}
	}

	fs.Infof(nil, "ğŸ“ [CACHE] æ‰«æå®Œæˆ - ç›®å½•: %s, å‘ç° %d ä¸ªè§†é¢‘æ–‡ä»¶", targetDir, len(files))
	return files, nil
}

// shouldSyncDirectory æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦åŒæ­¥ç›®å½•ï¼Œå¤§å¹…å‡å°‘APIè°ƒç”¨
func (spc *STRMPersistentCache) shouldSyncDirectory(dirPath string) bool {
	// 1. æ£€æŸ¥å…¨å±€åŒæ­¥æ—¶é—´
	timeSinceLastSync := time.Since(spc.lastSync)
	minSyncInterval := spc.getDirectorySyncInterval(dirPath)

	if timeSinceLastSync < minSyncInterval {
		fs.Debugf(nil, "â­ï¸ [SKIP] è·³è¿‡åŒæ­¥ %sï¼šè·ç¦»ä¸Šæ¬¡åŒæ­¥ %v < %v",
			dirPath, timeSinceLastSync, minSyncInterval)
		return false
	}

	// 2. æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å­˜åœ¨ä¸”è¾ƒæ–°
	cacheData, err := spc.loadFromDisk()
	if err == nil && cacheData != nil {
		cacheAge := time.Since(cacheData.UpdatedAt)
		maxCacheAge := spc.getDirectorySyncInterval(dirPath)

		if cacheAge < maxCacheAge {
			fs.Debugf(nil, "â­ï¸ [SKIP] è·³è¿‡åŒæ­¥ %sï¼šç¼“å­˜å¹´é¾„ %v < %v",
				dirPath, cacheAge, maxCacheAge)
			return false
		}
	}

	// 3. å¯¹äºæ·±å±‚ç›®å½•ï¼Œæ›´åŠ ä¿å®ˆ
	if strings.Count(dirPath, "/") > 3 {
		// æ·±å±‚ç›®å½•å¾ˆå°‘å˜åŒ–ï¼Œå»¶é•¿æ£€æŸ¥é—´éš”
		if timeSinceLastSync < 12*time.Hour {
			fs.Debugf(nil, "â­ï¸ [SKIP] è·³è¿‡æ·±å±‚ç›®å½•åŒæ­¥ %sï¼š%v < 12h",
				dirPath, timeSinceLastSync)
			return false
		}
	}

	// 4. å¯¹äºç‰¹æ®Šç›®å½•åï¼Œè·³è¿‡åŒæ­¥
	lowerPath := strings.ToLower(dirPath)
	skipDirs := []string{"temp", "tmp", "cache", "log", "logs", ".git", ".svn"}
	for _, skipDir := range skipDirs {
		if strings.Contains(lowerPath, skipDir) {
			fs.Debugf(nil, "â­ï¸ [SKIP] è·³è¿‡ç‰¹æ®Šç›®å½•åŒæ­¥: %s", dirPath)
			return false
		}
	}

	fs.Debugf(nil, "âœ… [SYNC] éœ€è¦åŒæ­¥ç›®å½•: %s", dirPath)
	return true
}
