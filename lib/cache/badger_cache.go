// Package cache provides a high-performance persistent cache implementation using BadgerDB
package cache

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/dgraph-io/badger/v3"
	"github.com/rclone/rclone/fs"
)

// PersistentCache æŒä¹…åŒ–ç¼“å­˜æ¥å£ï¼Œæ”¯æŒå¤šç§å®ç°
type PersistentCache interface {
	Set(key string, value interface{}, ttl time.Duration) error
	Get(key string, result interface{}) (bool, error)
	Delete(key string) error
	DeletePrefix(prefix string) error
	Clear() error
	Stats() map[string]interface{}
	ListAllKeys() ([]string, error)
	GetAllEntries() (map[string]interface{}, error)
	GetKeysByPrefix(prefix string) ([]string, error)
	Close() error
}

// BadgerCache åŸºäºBadgerDBçš„é«˜æ€§èƒ½æŒä¹…åŒ–ç¼“å­˜
type BadgerCache struct {
	db             *badger.DB
	name           string
	basePath       string
	operationCount int64 // ğŸ”§ è½»é‡çº§ä¼˜åŒ–ï¼šæ“ä½œè®¡æ•°å™¨ï¼Œç”¨äºå®šæœŸæ£€æŸ¥ç¼“å­˜å¤§å°
}

// CacheEntry ç¼“å­˜æ¡ç›®çš„é€šç”¨ç»“æ„
type CacheEntry struct {
	Key       string      `json:"key"`
	Value     interface{} `json:"value"`
	CreatedAt time.Time   `json:"created_at"`
	ExpiresAt time.Time   `json:"expires_at"`
}

// NewBadgerCache åˆ›å»ºæ–°çš„BadgerDBç¼“å­˜å®ä¾‹ - æ”¯æŒå¤šå®ä¾‹å†²çªå¤„ç†
func NewBadgerCache(name, basePath string) (*BadgerCache, error) {
	// åˆ›å»ºç¼“å­˜ç›®å½•
	cacheDir := filepath.Join(basePath, name)
	if err := os.MkdirAll(cacheDir, 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºç¼“å­˜ç›®å½•å¤±è´¥: %w", err)
	}

	// é…ç½®BadgerDBé€‰é¡¹ - è½»é‡çº§ä¼˜åŒ–ï¼šæé«˜æ€§èƒ½å’Œç¨³å®šæ€§
	opts := badger.DefaultOptions(cacheDir)
	opts.Logger = nil                // ç¦ç”¨BadgerDBæ—¥å¿—ï¼Œé¿å…å¹²æ‰°rcloneæ—¥å¿—
	opts.SyncWrites = false          // å¼‚æ­¥å†™å…¥ï¼Œæé«˜æ€§èƒ½
	opts.CompactL0OnClose = true     // å…³é—­æ—¶å‹ç¼©ï¼Œå‡å°‘ç£ç›˜å ç”¨
	opts.ValueLogFileSize = 64 << 20 // 64MB value logæ–‡ä»¶ï¼Œé€‚åˆå¤§æ–‡ä»¶ä¼ è¾“
	opts.MemTableSize = 64 << 20     // ğŸ”§ ä»32MBå¢åŠ åˆ°64MBï¼Œæé«˜å†™å…¥æ€§èƒ½
	opts.BaseTableSize = 8 << 20     // 8MBåŸºç¡€è¡¨å¤§å°
	opts.BaseLevelSize = 64 << 20    // 64MBåŸºç¡€çº§åˆ«å¤§å°
	opts.NumMemtables = 3            // ğŸ”§ ä»2å¢åŠ åˆ°3ï¼Œæé«˜å¹¶å‘æ€§èƒ½
	opts.NumLevelZeroTables = 2      // é™åˆ¶L0è¡¨æ•°é‡
	opts.NumLevelZeroTablesStall = 4 // L0è¡¨åœé¡¿é˜ˆå€¼
	opts.ValueThreshold = 512        // ğŸ”§ ä»1024å‡å°‘åˆ°512ï¼Œæ›´å¤šæ•°æ®å­˜å‚¨åœ¨LSMä¸­ï¼Œæé«˜è¯»å–æ€§èƒ½

	// å¤šå®ä¾‹å†²çªå¤„ç†ï¼šå°è¯•æ‰“å¼€æ•°æ®åº“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨åªè¯»æ¨¡å¼
	db, err := badger.Open(opts)
	if err != nil {
		// æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®åº“é”å®šé”™è¯¯ï¼ˆå¤šå®ä¾‹å†²çªï¼‰
		if isLockError(err) {
			fs.Infof(nil, "æ£€æµ‹åˆ°å¤šå®ä¾‹ç¼“å­˜å†²çªï¼Œå°è¯•åªè¯»æ¨¡å¼: %s", cacheDir)

			// å°è¯•åªè¯»æ¨¡å¼
			opts.ReadOnly = true
			db, err = badger.Open(opts)
			if err != nil {
				fs.Infof(nil, "åªè¯»æ¨¡å¼ä¹Ÿå¤±è´¥ï¼Œåˆ›å»ºæ¨¡æ‹Ÿç¼“å­˜: %s, é”™è¯¯: %v", cacheDir, err)
				// åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„BadgerCacheï¼Œæ‰€æœ‰æ“ä½œéƒ½æ˜¯ç©ºæ“ä½œ
				return &BadgerCache{
					db:       nil, // ç©ºæ•°æ®åº“æŒ‡é’ˆï¼Œè¡¨ç¤ºç¦ç”¨çŠ¶æ€
					name:     name + "_disabled",
					basePath: basePath,
				}, nil
			}
			fs.Infof(nil, "ä½¿ç”¨åªè¯»ç¼“å­˜æ¨¡å¼: %s", cacheDir)
		} else {
			return nil, fmt.Errorf("æ‰“å¼€BadgerDBå¤±è´¥: %w", err)
		}
	}

	cache := &BadgerCache{
		db:       db,
		name:     name,
		basePath: basePath,
	}

	// åªæœ‰åœ¨éåªè¯»æ¨¡å¼ä¸‹æ‰å¯åŠ¨åå°åƒåœ¾å›æ”¶
	if !opts.ReadOnly {
		go cache.runGC()
	}

	fs.Debugf(nil, "BadgerDBç¼“å­˜åˆå§‹åŒ–æˆåŠŸ: %s (åªè¯»æ¨¡å¼: %v)", cacheDir, opts.ReadOnly)
	return cache, nil
}

// Set è®¾ç½®ç¼“å­˜å€¼ï¼Œæ”¯æŒTTL
func (c *BadgerCache) Set(key string, value interface{}, ttl time.Duration) error {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œé™é»˜å¿½ç•¥
	if c.db == nil {
		return nil
	}

	// ğŸ”§ è½»é‡çº§ä¼˜åŒ–ï¼šå®šæœŸæ£€æŸ¥ç¼“å­˜å¤§å°
	c.operationCount++
	if c.operationCount%1000 == 0 {
		c.checkCacheSize()
	}

	entry := CacheEntry{
		Key:       key,
		Value:     value,
		CreatedAt: time.Now(),
		ExpiresAt: time.Now().Add(ttl),
	}

	data, err := json.Marshal(entry)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–ç¼“å­˜æ¡ç›®å¤±è´¥: %w", err)
	}

	return c.db.Update(func(txn *badger.Txn) error {
		e := badger.NewEntry([]byte(key), data).WithTTL(ttl)
		return txn.SetEntry(e)
	})
}

// Get è·å–ç¼“å­˜å€¼
func (c *BadgerCache) Get(key string, result interface{}) (bool, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œæ€»æ˜¯è¿”å›æœªæ‰¾åˆ°
	if c.db == nil {
		return false, nil
	}

	var found bool
	var entry CacheEntry

	err := c.db.View(func(txn *badger.Txn) error {
		item, err := txn.Get([]byte(key))
		if err != nil {
			if err == badger.ErrKeyNotFound {
				return nil // é”®ä¸å­˜åœ¨ï¼Œä¸æ˜¯é”™è¯¯
			}
			return err
		}

		return item.Value(func(val []byte) error {
			if err := json.Unmarshal(val, &entry); err != nil {
				return fmt.Errorf("ååºåˆ—åŒ–ç¼“å­˜æ¡ç›®å¤±è´¥: %w", err)
			}
			found = true
			return nil
		})
	})

	if err != nil {
		return false, err
	}

	if !found {
		return false, nil
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆåŒé‡ä¿é™©ï¼ŒBadgerDB TTL + åº”ç”¨å±‚æ£€æŸ¥ï¼‰
	if time.Now().After(entry.ExpiresAt) {
		// å¼‚æ­¥åˆ é™¤è¿‡æœŸæ¡ç›®
		go c.Delete(key)
		return false, nil
	}

	// å°†å€¼ååºåˆ—åŒ–åˆ°resultä¸­
	valueData, err := json.Marshal(entry.Value)
	if err != nil {
		return false, fmt.Errorf("åºåˆ—åŒ–ç¼“å­˜å€¼å¤±è´¥: %w", err)
	}

	if err := json.Unmarshal(valueData, result); err != nil {
		return false, fmt.Errorf("ååºåˆ—åŒ–ç¼“å­˜å€¼å¤±è´¥: %w", err)
	}

	return true, nil
}

// GetBool è·å–å¸ƒå°”å€¼çš„ä¾¿æ·æ–¹æ³•
func (c *BadgerCache) GetBool(key string) (bool, bool) {
	var result bool
	found, err := c.Get(key, &result)
	if err != nil {
		fs.Debugf(nil, "è·å–å¸ƒå°”ç¼“å­˜å¤±è´¥ %s: %v", key, err)
		return false, false
	}
	return result, found
}

// SetBool è®¾ç½®å¸ƒå°”å€¼çš„ä¾¿æ·æ–¹æ³•
func (c *BadgerCache) SetBool(key string, value bool, ttl time.Duration) error {
	return c.Set(key, value, ttl)
}

// Delete åˆ é™¤ç¼“å­˜æ¡ç›®
func (c *BadgerCache) Delete(key string) error {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œé™é»˜å¿½ç•¥
	if c.db == nil {
		return nil
	}
	return c.db.Update(func(txn *badger.Txn) error {
		return txn.Delete([]byte(key))
	})
}

// DeletePrefix åˆ é™¤æŒ‡å®šå‰ç¼€çš„æ‰€æœ‰ç¼“å­˜æ¡ç›®
func (c *BadgerCache) DeletePrefix(prefix string) error {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œé™é»˜å¿½ç•¥
	if c.db == nil {
		return nil
	}
	return c.db.Update(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false
		it := txn.NewIterator(opts)
		defer it.Close()

		prefixBytes := []byte(prefix)
		for it.Seek(prefixBytes); it.ValidForPrefix(prefixBytes); it.Next() {
			if err := txn.Delete(it.Item().Key()); err != nil {
				return err
			}
		}
		return nil
	})
}

// Clear æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
func (c *BadgerCache) Clear() error {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œé™é»˜å¿½ç•¥
	if c.db == nil {
		return nil
	}
	return c.db.DropAll()
}

// Stats è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (c *BadgerCache) Stats() map[string]interface{} {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç¦ç”¨çŠ¶æ€ä¿¡æ¯
	if c.db == nil {
		return map[string]interface{}{
			"name":       c.name,
			"lsm_size":   0,
			"vlog_size":  0,
			"total_size": 0,
			"status":     "disabled",
		}
	}
	lsm, vlog := c.db.Size()
	return map[string]interface{}{
		"name":       c.name,
		"lsm_size":   lsm,
		"vlog_size":  vlog,
		"total_size": lsm + vlog,
		"status":     "active",
	}
}

// ListAllKeys åˆ—å‡ºæ‰€æœ‰ç¼“å­˜é”®
func (c *BadgerCache) ListAllKeys() ([]string, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
	if c.db == nil {
		return []string{}, nil
	}

	var keys []string

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false // åªéœ€è¦é”®ï¼Œä¸éœ€è¦å€¼
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()
			key := string(item.Key())
			keys = append(keys, key)
		}
		return nil
	})

	return keys, err
}

// GetAllEntries è·å–æ‰€æœ‰ç¼“å­˜æ¡ç›®
func (c *BadgerCache) GetAllEntries() (map[string]interface{}, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç©ºæ˜ å°„
	if c.db == nil {
		return map[string]interface{}{}, nil
	}

	entries := make(map[string]interface{})

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()
			key := string(item.Key())

			// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
			if item.ExpiresAt() > 0 && item.ExpiresAt() < uint64(time.Now().Unix()) {
				continue // è·³è¿‡è¿‡æœŸçš„æ¡ç›®
			}

			err := item.Value(func(val []byte) error {
				// å°è¯•è§£æä¸ºä¸åŒç±»å‹
				var value interface{}

				// é¦–å…ˆå°è¯•è§£æä¸ºJSON
				if err := json.Unmarshal(val, &value); err == nil {
					entries[key] = value
				} else {
					// å¦‚æœä¸æ˜¯JSONï¼Œå­˜å‚¨ä¸ºå­—ç¬¦ä¸²
					entries[key] = string(val)
				}
				return nil
			})

			if err != nil {
				entries[key] = fmt.Sprintf("è¯»å–é”™è¯¯: %v", err)
			}
		}
		return nil
	})

	return entries, err
}

// GetKeysByPrefix æ ¹æ®å‰ç¼€è·å–é”®
func (c *BadgerCache) GetKeysByPrefix(prefix string) ([]string, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
	if c.db == nil {
		return []string{}, nil
	}

	var keys []string

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false
		it := txn.NewIterator(opts)
		defer it.Close()

		prefixBytes := []byte(prefix)
		for it.Seek(prefixBytes); it.ValidForPrefix(prefixBytes); it.Next() {
			item := it.Item()
			key := string(item.Key())
			keys = append(keys, key)
		}
		return nil
	})

	return keys, err
}

// Close å…³é—­ç¼“å­˜æ•°æ®åº“
func (c *BadgerCache) Close() error {
	if c.db != nil {
		fs.Debugf(nil, "å…³é—­BadgerDBç¼“å­˜: %s", c.name)
		return c.db.Close()
	}
	return nil
}

// runGC è¿è¡Œåå°åƒåœ¾å›æ”¶ - ä¼˜åŒ–é¢‘ç‡å’Œé˜ˆå€¼
func (c *BadgerCache) runGC() {
	ticker := time.NewTicker(15 * time.Minute) // å‡å°‘GCé¢‘ç‡ï¼Œä»5åˆ†é’Ÿæ”¹ä¸º15åˆ†é’Ÿ
	defer ticker.Stop()

	for range ticker.C {
		// ä½¿ç”¨æ›´ä¿å®ˆçš„GCé˜ˆå€¼ï¼Œå‡å°‘å†…å­˜å‹åŠ›
		err := c.db.RunValueLogGC(0.5) // ä»0.7æ”¹ä¸º0.5ï¼Œæ›´ç§¯æåœ°å›æ”¶
		if err != nil && err != badger.ErrNoRewrite {
			fs.Debugf(nil, "BadgerDBåƒåœ¾å›æ”¶å¤±è´¥ %s: %v", c.name, err)
		} else if err == nil {
			fs.Debugf(nil, "BadgerDBåƒåœ¾å›æ”¶å®Œæˆ %s", c.name)
		}
	}
}

// checkCacheSize æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œè¶…è¿‡é™åˆ¶æ—¶æ¸…ç†
// ğŸ”§ è½»é‡çº§ä¼˜åŒ–ï¼šç®€å•çš„ç¼“å­˜å¤§å°æ§åˆ¶æœºåˆ¶
func (c *BadgerCache) checkCacheSize() {
	if c.db == nil {
		return
	}

	// è·å–æ•°æ®åº“å¤§å°ä¿¡æ¯
	lsm, vlog := c.db.Size()
	totalSize := lsm + vlog

	// è®¾ç½®æœ€å¤§ç¼“å­˜å¤§å°ä¸º100MB
	const maxCacheSize = 100 << 20 // 100MB

	if totalSize > maxCacheSize {
		fs.Debugf(nil, "ç¼“å­˜ %s å¤§å°è¶…è¿‡é™åˆ¶ (%d MB)ï¼Œæ‰§è¡Œæ¸…ç†", c.name, totalSize>>20)
		// ç®€å•ç­–ç•¥ï¼šè¶…è¿‡é™åˆ¶å°±æ¸…ç©ºç¼“å­˜
		if err := c.Clear(); err != nil {
			fs.Debugf(nil, "æ¸…ç†ç¼“å­˜ %s å¤±è´¥: %v", c.name, err)
		} else {
			fs.Debugf(nil, "å·²æ¸…ç†ç¼“å­˜ %s", c.name)
		}
	}
}

// GetCacheDir è·å–ç¼“å­˜ç›®å½•è·¯å¾„ - æ”¯æŒå¤šå®ä¾‹å…±äº«
func GetCacheDir(name string) string {
	// ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ç¼“å­˜ç›®å½• - æ‰€æœ‰å®ä¾‹å…±äº«åŒä¸€è·¯å¾„
	if userCacheDir, err := os.UserCacheDir(); err == nil {
		return filepath.Join(userCacheDir, "rclone", name)
	}

	// å›é€€åˆ°ä¸´æ—¶ç›®å½•
	return filepath.Join(os.TempDir(), "rclone_cache", name)
}

// CleanupExpiredCaches æ¸…ç†è¿‡æœŸçš„ç¼“å­˜ç›®å½•ï¼ˆå¯é€‰çš„ç»´æŠ¤åŠŸèƒ½ï¼‰
func CleanupExpiredCaches(basePath string, maxAge time.Duration) error {
	entries, err := os.ReadDir(basePath)
	if err != nil {
		return err
	}

	cutoff := time.Now().Add(-maxAge)
	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		info, err := entry.Info()
		if err != nil {
			continue
		}

		if info.ModTime().Before(cutoff) {
			cachePath := filepath.Join(basePath, entry.Name())
			fs.Debugf(nil, "æ¸…ç†è¿‡æœŸç¼“å­˜ç›®å½•: %s", cachePath)
			os.RemoveAll(cachePath)
		}
	}

	return nil
}

// isLockError æ£€æŸ¥é”™è¯¯æ˜¯å¦ä¸ºæ•°æ®åº“é”å®šé”™è¯¯ï¼ˆå¤šå®ä¾‹å†²çªï¼‰
func isLockError(err error) bool {
	if err == nil {
		return false
	}
	errStr := strings.ToLower(err.Error())
	// æ£€æŸ¥å¸¸è§çš„æ•°æ®åº“é”å®šé”™è¯¯ä¿¡æ¯
	lockKeywords := []string{
		"resource temporarily unavailable",
		"database is locked",
		"cannot acquire directory lock",
		"lock",
		"resource busy",
	}

	for _, keyword := range lockKeywords {
		if strings.Contains(errStr, keyword) {
			return true
		}
	}
	return false
}

// NullCache ç©ºç¼“å­˜å®ç°ï¼Œç”¨äºå¤šå®ä¾‹å†²çªæ—¶çš„é™çº§æ–¹æ¡ˆ
type NullCache struct {
	name     string
	basePath string
}

// NewNullCache åˆ›å»ºç©ºç¼“å­˜å®ä¾‹
func NewNullCache(name, basePath string) *NullCache {
	return &NullCache{
		name:     name,
		basePath: basePath,
	}
}

// Set ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Set(key string, value interface{}, ttl time.Duration) error {
	return nil // é™é»˜å¿½ç•¥
}

// Get ç©ºå®ç°ï¼Œæ€»æ˜¯è¿”å›æœªæ‰¾åˆ°
func (c *NullCache) Get(key string, result interface{}) (bool, error) {
	return false, nil // æ€»æ˜¯æœªæ‰¾åˆ°
}

// Delete ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Delete(key string) error {
	return nil // é™é»˜å¿½ç•¥
}

// DeletePrefix ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) DeletePrefix(prefix string) error {
	return nil // é™é»˜å¿½ç•¥
}

// Clear ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Clear() error {
	return nil // é™é»˜å¿½ç•¥
}

// Stats è¿”å›ç©ºç»Ÿè®¡ä¿¡æ¯
func (c *NullCache) Stats() map[string]interface{} {
	return map[string]interface{}{
		"name":       c.name + "_null",
		"lsm_size":   0,
		"vlog_size":  0,
		"total_size": 0,
		"type":       "null_cache",
	}
}

// ListAllKeys è¿”å›ç©ºé”®åˆ—è¡¨
func (c *NullCache) ListAllKeys() ([]string, error) {
	return []string{}, nil
}

// GetAllEntries è¿”å›ç©ºæ¡ç›®åˆ—è¡¨
func (c *NullCache) GetAllEntries() (map[string]interface{}, error) {
	return map[string]interface{}{}, nil
}

// GetKeysByPrefix è¿”å›ç©ºé”®åˆ—è¡¨
func (c *NullCache) GetKeysByPrefix(prefix string) ([]string, error) {
	return []string{}, nil
}

// Close ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Close() error {
	return nil // é™é»˜å¿½ç•¥
}
