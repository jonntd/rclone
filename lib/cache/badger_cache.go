// Package cache provides a high-performance persistent cache implementation using BadgerDB
package cache

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/dgraph-io/badger/v3"
	"github.com/rclone/rclone/fs"
)

// PersistentCache æŒä¹…åŒ–ç¼“å­˜æ¥å£ï¼Œæ”¯æŒå¤šç§å®ç°
type PersistentCache interface {
	Set(key string, value interface{}, ttl time.Duration) error
	Get(key string, result interface{}) (bool, error)
	Delete(key string) error
	DeletePrefix(prefix string) error
	Clear() error
	Stats() map[string]interface{}
	ListAllKeys() ([]string, error)
	GetAllEntries() (map[string]interface{}, error)
	GetKeysByPrefix(prefix string) ([]string, error)
	Close() error
}

// BadgerCache åŸºäºBadgerDBçš„é«˜æ€§èƒ½æŒä¹…åŒ–ç¼“å­˜
// ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ å†…å­˜å¤‡ä»½æœºåˆ¶ï¼Œç¡®ä¿å¤šå®ä¾‹å†²çªæ—¶ä»å¯ç”¨
type BadgerCache struct {
	db             *badger.DB
	name           string
	basePath       string
	operationCount int64 // ğŸ”§ è½»é‡çº§ä¼˜åŒ–ï¼šæ“ä½œè®¡æ•°å™¨ï¼Œç”¨äºå®šæœŸæ£€æŸ¥ç¼“å­˜å¤§å°

	// ğŸ”§ æ–°å¢ï¼šå†…å­˜å¤‡ä»½æœºåˆ¶
	memoryBackup   map[string]*CacheEntry // å†…å­˜å¤‡ä»½å­˜å‚¨
	memoryMutex    sync.RWMutex           // å†…å­˜å¤‡ä»½çš„è¯»å†™é”
	isMemoryMode   bool                   // æ˜¯å¦å¤„äºå†…å­˜æ¨¡å¼
	maxMemoryItems int                    // å†…å­˜æ¨¡å¼ä¸‹çš„æœ€å¤§æ¡ç›®æ•°
}

// CacheEntry ç¼“å­˜æ¡ç›®çš„é€šç”¨ç»“æ„
type CacheEntry struct {
	Key       string      `json:"key"`
	Value     interface{} `json:"value"`
	CreatedAt time.Time   `json:"created_at"`
	ExpiresAt time.Time   `json:"expires_at"`
}

// NewBadgerCache åˆ›å»ºæ–°çš„BadgerDBç¼“å­˜å®ä¾‹ - æ”¯æŒå¤šå®ä¾‹å†²çªå¤„ç†
func NewBadgerCache(name, basePath string) (*BadgerCache, error) {
	// åˆ›å»ºç¼“å­˜ç›®å½•
	cacheDir := filepath.Join(basePath, name)
	if err := os.MkdirAll(cacheDir, 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºç¼“å­˜ç›®å½•å¤±è´¥: %w", err)
	}

	// é…ç½®BadgerDBé€‰é¡¹ - è½»é‡çº§ä¼˜åŒ–ï¼šæé«˜æ€§èƒ½å’Œç¨³å®šæ€§
	opts := badger.DefaultOptions(cacheDir)
	opts.Logger = nil                // ç¦ç”¨BadgerDBæ—¥å¿—ï¼Œé¿å…å¹²æ‰°rcloneæ—¥å¿—
	opts.SyncWrites = false          // å¼‚æ­¥å†™å…¥ï¼Œæé«˜æ€§èƒ½
	opts.CompactL0OnClose = true     // å…³é—­æ—¶å‹ç¼©ï¼Œå‡å°‘ç£ç›˜å ç”¨
	opts.ValueLogFileSize = 64 << 20 // 64MB value logæ–‡ä»¶ï¼Œé€‚åˆå¤§æ–‡ä»¶ä¼ è¾“
	opts.MemTableSize = 64 << 20     // ğŸ”§ ä»32MBå¢åŠ åˆ°64MBï¼Œæé«˜å†™å…¥æ€§èƒ½
	opts.BaseTableSize = 8 << 20     // 8MBåŸºç¡€è¡¨å¤§å°
	opts.BaseLevelSize = 64 << 20    // 64MBåŸºç¡€çº§åˆ«å¤§å°
	opts.NumMemtables = 3            // ğŸ”§ ä»2å¢åŠ åˆ°3ï¼Œæé«˜å¹¶å‘æ€§èƒ½
	opts.NumLevelZeroTables = 2      // é™åˆ¶L0è¡¨æ•°é‡
	opts.NumLevelZeroTablesStall = 4 // L0è¡¨åœé¡¿é˜ˆå€¼
	opts.ValueThreshold = 512        // ğŸ”§ ä»1024å‡å°‘åˆ°512ï¼Œæ›´å¤šæ•°æ®å­˜å‚¨åœ¨LSMä¸­ï¼Œæé«˜è¯»å–æ€§èƒ½

	// ğŸ”§ ä¼˜åŒ–ï¼šå¤šå®ä¾‹å†²çªå¤„ç†ï¼Œä½¿ç”¨å†…å­˜å¤‡ä»½è€Œä¸æ˜¯å®Œå…¨ç¦ç”¨
	db, err := badger.Open(opts)
	if err != nil {
		// æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®åº“é”å®šé”™è¯¯ï¼ˆå¤šå®ä¾‹å†²çªï¼‰
		if isLockError(err) {
			fs.Infof(nil, "æ£€æµ‹åˆ°å¤šå®ä¾‹ç¼“å­˜å†²çªï¼Œå°è¯•åªè¯»æ¨¡å¼: %s", cacheDir)

			// å°è¯•åªè¯»æ¨¡å¼
			opts.ReadOnly = true
			db, err = badger.Open(opts)
			if err != nil {
				fs.Infof(nil, "åªè¯»æ¨¡å¼ä¹Ÿå¤±è´¥ï¼Œå¯ç”¨å†…å­˜å¤‡ä»½æ¨¡å¼: %s, é”™è¯¯: %v", cacheDir, err)
				// ğŸ”§ åˆ›å»ºå†…å­˜å¤‡ä»½æ¨¡å¼çš„BadgerCacheï¼Œè€Œä¸æ˜¯å®Œå…¨ç¦ç”¨
				return &BadgerCache{
					db:             nil, // ç©ºæ•°æ®åº“æŒ‡é’ˆï¼Œè¡¨ç¤ºBadgerDBä¸å¯ç”¨
					name:           name + "_memory",
					basePath:       basePath,
					memoryBackup:   make(map[string]*CacheEntry),
					isMemoryMode:   true,
					maxMemoryItems: 1000, // é™åˆ¶å†…å­˜æ¡ç›®æ•°ï¼Œé¿å…å†…å­˜æ³„æ¼
				}, nil
			}
			fs.Infof(nil, "ä½¿ç”¨åªè¯»ç¼“å­˜æ¨¡å¼: %s", cacheDir)
		} else {
			return nil, fmt.Errorf("æ‰“å¼€BadgerDBå¤±è´¥: %w", err)
		}
	}

	cache := &BadgerCache{
		db:             db,
		name:           name,
		basePath:       basePath,
		memoryBackup:   make(map[string]*CacheEntry),
		isMemoryMode:   false,
		maxMemoryItems: 1000,
	}

	// åªæœ‰åœ¨éåªè¯»æ¨¡å¼ä¸‹æ‰å¯åŠ¨åå°åƒåœ¾å›æ”¶
	if !opts.ReadOnly {
		go cache.runGC()
	}

	fs.Debugf(nil, "BadgerDBç¼“å­˜åˆå§‹åŒ–æˆåŠŸ: %s (åªè¯»æ¨¡å¼: %v)", cacheDir, opts.ReadOnly)
	return cache, nil
}

// Set è®¾ç½®ç¼“å­˜å€¼ï¼Œæ”¯æŒTTL
// ğŸ”§ ä¼˜åŒ–ï¼šæ”¯æŒå†…å­˜å¤‡ä»½æ¨¡å¼
func (c *BadgerCache) Set(key string, value interface{}, ttl time.Duration) error {
	// ğŸ”§ å¦‚æœå¤„äºå†…å­˜æ¨¡å¼ï¼Œä½¿ç”¨å†…å­˜å¤‡ä»½
	if c.isMemoryMode || c.db == nil {
		return c.setToMemory(key, value, ttl)
	}

	// ğŸ”§ è½»é‡çº§ä¼˜åŒ–ï¼šå®šæœŸæ£€æŸ¥ç¼“å­˜å¤§å°
	c.operationCount++
	if c.operationCount%1000 == 0 {
		c.checkCacheSize()
	}

	entry := CacheEntry{
		Key:       key,
		Value:     value,
		CreatedAt: time.Now(),
		ExpiresAt: time.Now().Add(ttl),
	}

	data, err := json.Marshal(entry)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–ç¼“å­˜æ¡ç›®å¤±è´¥: %w", err)
	}

	return c.db.Update(func(txn *badger.Txn) error {
		e := badger.NewEntry([]byte(key), data).WithTTL(ttl)
		return txn.SetEntry(e)
	})
}

// Get è·å–ç¼“å­˜å€¼
// ğŸ”§ ä¼˜åŒ–ï¼šæ”¯æŒå†…å­˜å¤‡ä»½æ¨¡å¼
func (c *BadgerCache) Get(key string, result interface{}) (bool, error) {
	// ğŸ”§ å¦‚æœå¤„äºå†…å­˜æ¨¡å¼ï¼Œä»å†…å­˜å¤‡ä»½è·å–
	if c.isMemoryMode || c.db == nil {
		return c.getFromMemory(key, result)
	}

	var found bool
	var entry CacheEntry

	err := c.db.View(func(txn *badger.Txn) error {
		item, err := txn.Get([]byte(key))
		if err != nil {
			if err == badger.ErrKeyNotFound {
				return nil // é”®ä¸å­˜åœ¨ï¼Œä¸æ˜¯é”™è¯¯
			}
			return err
		}

		return item.Value(func(val []byte) error {
			if err := json.Unmarshal(val, &entry); err != nil {
				return fmt.Errorf("ååºåˆ—åŒ–ç¼“å­˜æ¡ç›®å¤±è´¥: %w", err)
			}
			found = true
			return nil
		})
	})

	if err != nil {
		return false, err
	}

	if !found {
		return false, nil
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆåŒé‡ä¿é™©ï¼ŒBadgerDB TTL + åº”ç”¨å±‚æ£€æŸ¥ï¼‰
	if time.Now().After(entry.ExpiresAt) {
		// å¼‚æ­¥åˆ é™¤è¿‡æœŸæ¡ç›®
		go c.Delete(key)
		return false, nil
	}

	// å°†å€¼ååºåˆ—åŒ–åˆ°resultä¸­
	valueData, err := json.Marshal(entry.Value)
	if err != nil {
		return false, fmt.Errorf("åºåˆ—åŒ–ç¼“å­˜å€¼å¤±è´¥: %w", err)
	}

	if err := json.Unmarshal(valueData, result); err != nil {
		return false, fmt.Errorf("ååºåˆ—åŒ–ç¼“å­˜å€¼å¤±è´¥: %w", err)
	}

	return true, nil
}

// GetBool è·å–å¸ƒå°”å€¼çš„ä¾¿æ·æ–¹æ³•
func (c *BadgerCache) GetBool(key string) (bool, bool) {
	var result bool
	found, err := c.Get(key, &result)
	if err != nil {
		fs.Debugf(nil, "è·å–å¸ƒå°”ç¼“å­˜å¤±è´¥ %s: %v", key, err)
		return false, false
	}
	return result, found
}

// SetBool è®¾ç½®å¸ƒå°”å€¼çš„ä¾¿æ·æ–¹æ³•
func (c *BadgerCache) SetBool(key string, value bool, ttl time.Duration) error {
	return c.Set(key, value, ttl)
}

// Delete åˆ é™¤ç¼“å­˜æ¡ç›®
// ğŸ”§ ä¼˜åŒ–ï¼šæ”¯æŒå†…å­˜å¤‡ä»½æ¨¡å¼
func (c *BadgerCache) Delete(key string) error {
	// ğŸ”§ å¦‚æœå¤„äºå†…å­˜æ¨¡å¼ï¼Œä»å†…å­˜å¤‡ä»½åˆ é™¤
	if c.isMemoryMode || c.db == nil {
		c.memoryMutex.Lock()
		delete(c.memoryBackup, key)
		c.memoryMutex.Unlock()
		fs.Debugf(nil, "å†…å­˜å¤‡ä»½åˆ é™¤: %s", key)
		return nil
	}

	return c.db.Update(func(txn *badger.Txn) error {
		return txn.Delete([]byte(key))
	})
}

// DeletePrefix åˆ é™¤æŒ‡å®šå‰ç¼€çš„æ‰€æœ‰ç¼“å­˜æ¡ç›®
// ğŸ”§ ä¼˜åŒ–ï¼šæ”¯æŒå†…å­˜å¤‡ä»½æ¨¡å¼
func (c *BadgerCache) DeletePrefix(prefix string) error {
	// ğŸ”§ å¦‚æœå¤„äºå†…å­˜æ¨¡å¼ï¼Œä»å†…å­˜å¤‡ä»½åˆ é™¤
	if c.isMemoryMode || c.db == nil {
		c.memoryMutex.Lock()
		defer c.memoryMutex.Unlock()

		keysToDelete := make([]string, 0)
		for key := range c.memoryBackup {
			if strings.HasPrefix(key, prefix) {
				keysToDelete = append(keysToDelete, key)
			}
		}

		for _, key := range keysToDelete {
			delete(c.memoryBackup, key)
		}

		fs.Debugf(nil, "å†…å­˜å¤‡ä»½åˆ é™¤å‰ç¼€ %s: %dä¸ªæ¡ç›®", prefix, len(keysToDelete))
		return nil
	}
	return c.db.Update(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false
		it := txn.NewIterator(opts)
		defer it.Close()

		prefixBytes := []byte(prefix)
		for it.Seek(prefixBytes); it.ValidForPrefix(prefixBytes); it.Next() {
			if err := txn.Delete(it.Item().Key()); err != nil {
				return err
			}
		}
		return nil
	})
}

// Clear æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
func (c *BadgerCache) Clear() error {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œé™é»˜å¿½ç•¥
	if c.db == nil {
		return nil
	}
	return c.db.DropAll()
}

// Stats è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (c *BadgerCache) Stats() map[string]interface{} {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç¦ç”¨çŠ¶æ€ä¿¡æ¯
	if c.db == nil {
		return map[string]interface{}{
			"name":       c.name,
			"lsm_size":   0,
			"vlog_size":  0,
			"total_size": 0,
			"status":     "disabled",
		}
	}
	lsm, vlog := c.db.Size()
	return map[string]interface{}{
		"name":       c.name,
		"lsm_size":   lsm,
		"vlog_size":  vlog,
		"total_size": lsm + vlog,
		"status":     "active",
	}
}

// ListAllKeys åˆ—å‡ºæ‰€æœ‰ç¼“å­˜é”®
func (c *BadgerCache) ListAllKeys() ([]string, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
	if c.db == nil {
		return []string{}, nil
	}

	var keys []string

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false // åªéœ€è¦é”®ï¼Œä¸éœ€è¦å€¼
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()
			key := string(item.Key())
			keys = append(keys, key)
		}
		return nil
	})

	return keys, err
}

// GetAllEntries è·å–æ‰€æœ‰ç¼“å­˜æ¡ç›®
func (c *BadgerCache) GetAllEntries() (map[string]interface{}, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç©ºæ˜ å°„
	if c.db == nil {
		return map[string]interface{}{}, nil
	}

	entries := make(map[string]interface{})

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()
			key := string(item.Key())

			// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
			if item.ExpiresAt() > 0 && item.ExpiresAt() < uint64(time.Now().Unix()) {
				continue // è·³è¿‡è¿‡æœŸçš„æ¡ç›®
			}

			err := item.Value(func(val []byte) error {
				// å°è¯•è§£æä¸ºä¸åŒç±»å‹
				var value interface{}

				// é¦–å…ˆå°è¯•è§£æä¸ºJSON
				if err := json.Unmarshal(val, &value); err == nil {
					entries[key] = value
				} else {
					// å¦‚æœä¸æ˜¯JSONï¼Œå­˜å‚¨ä¸ºå­—ç¬¦ä¸²
					entries[key] = string(val)
				}
				return nil
			})

			if err != nil {
				entries[key] = fmt.Sprintf("è¯»å–é”™è¯¯: %v", err)
			}
		}
		return nil
	})

	return entries, err
}

// GetKeysByPrefix æ ¹æ®å‰ç¼€è·å–é”®
func (c *BadgerCache) GetKeysByPrefix(prefix string) ([]string, error) {
	// å¦‚æœæ•°æ®åº“è¢«ç¦ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
	if c.db == nil {
		return []string{}, nil
	}

	var keys []string

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false
		it := txn.NewIterator(opts)
		defer it.Close()

		prefixBytes := []byte(prefix)
		for it.Seek(prefixBytes); it.ValidForPrefix(prefixBytes); it.Next() {
			item := it.Item()
			key := string(item.Key())
			keys = append(keys, key)
		}
		return nil
	})

	return keys, err
}

// Close å…³é—­ç¼“å­˜æ•°æ®åº“
func (c *BadgerCache) Close() error {
	if c.db != nil {
		fs.Debugf(nil, "å…³é—­BadgerDBç¼“å­˜: %s", c.name)
		return c.db.Close()
	}
	return nil
}

// runGC è¿è¡Œåå°åƒåœ¾å›æ”¶ - ä¼˜åŒ–é¢‘ç‡å’Œé˜ˆå€¼
func (c *BadgerCache) runGC() {
	ticker := time.NewTicker(15 * time.Minute) // å‡å°‘GCé¢‘ç‡ï¼Œä»5åˆ†é’Ÿæ”¹ä¸º15åˆ†é’Ÿ
	defer ticker.Stop()

	for range ticker.C {
		// ä½¿ç”¨æ›´ä¿å®ˆçš„GCé˜ˆå€¼ï¼Œå‡å°‘å†…å­˜å‹åŠ›
		err := c.db.RunValueLogGC(0.5) // ä»0.7æ”¹ä¸º0.5ï¼Œæ›´ç§¯æåœ°å›æ”¶
		if err != nil && err != badger.ErrNoRewrite {
			fs.Debugf(nil, "BadgerDBåƒåœ¾å›æ”¶å¤±è´¥ %s: %v", c.name, err)
		} else if err == nil {
			fs.Debugf(nil, "BadgerDBåƒåœ¾å›æ”¶å®Œæˆ %s", c.name)
		}
	}
}

// checkCacheSize æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œè¶…è¿‡é™åˆ¶æ—¶æ™ºèƒ½æ¸…ç†
// ğŸ”§ ä¿®å¤ç¼“å­˜ç­–ç•¥ï¼šå®ç°LRUæ·˜æ±°æœºåˆ¶ï¼Œæ›¿æ¢ç²—æš´çš„å…¨éƒ¨æ¸…ç©º
func (c *BadgerCache) checkCacheSize() {
	if c.db == nil {
		return
	}

	// è·å–æ•°æ®åº“å¤§å°ä¿¡æ¯
	lsm, vlog := c.db.Size()
	totalSize := lsm + vlog

	// ğŸ”§ ä¼˜åŒ–ï¼šæé«˜ç¼“å­˜å¤§å°é™åˆ¶åˆ°200MBï¼Œå‡å°‘æ¸…ç†é¢‘ç‡
	const maxCacheSize = 200 << 20 // 200MB
	const targetSize = 150 << 20   // æ¸…ç†åˆ°150MB

	if totalSize > maxCacheSize {
		fs.Debugf(nil, "ç¼“å­˜ %s å¤§å°è¶…è¿‡é™åˆ¶ (%d MB)ï¼Œå¼€å§‹æ™ºèƒ½æ¸…ç†", c.name, totalSize>>20)

		// ğŸ”§ æ™ºèƒ½æ¸…ç†ï¼šä½¿ç”¨LRUç­–ç•¥æ¸…ç†æœ€æ—§çš„æ¡ç›®
		if err := c.smartCleanup(targetSize); err != nil {
			fs.Debugf(nil, "æ™ºèƒ½æ¸…ç†ç¼“å­˜ %s å¤±è´¥ï¼Œå›é€€åˆ°å…¨éƒ¨æ¸…ç©º: %v", c.name, err)
			// å¦‚æœæ™ºèƒ½æ¸…ç†å¤±è´¥ï¼Œå›é€€åˆ°å…¨éƒ¨æ¸…ç©º
			if clearErr := c.Clear(); clearErr != nil {
				fs.Debugf(nil, "æ¸…ç†ç¼“å­˜ %s å¤±è´¥: %v", c.name, clearErr)
			}
		} else {
			// æ£€æŸ¥æ¸…ç†æ•ˆæœ
			newLsm, newVlog := c.db.Size()
			newTotalSize := newLsm + newVlog
			fs.Debugf(nil, "æ™ºèƒ½æ¸…ç†ç¼“å­˜ %s å®Œæˆ: %d MB -> %d MB",
				c.name, totalSize>>20, newTotalSize>>20)
		}
	}
}

// smartCleanup æ™ºèƒ½ç¼“å­˜æ¸…ç†ï¼Œä½¿ç”¨LRUç­–ç•¥
// ğŸ”§ æ–°å¢ï¼šå®ç°åŸºäºè®¿é—®æ—¶é—´çš„LRUæ·˜æ±°æœºåˆ¶
func (c *BadgerCache) smartCleanup(targetSize int64) error {
	if c.db == nil {
		return nil
	}

	// æ”¶é›†æ‰€æœ‰ç¼“å­˜æ¡ç›®åŠå…¶è®¿é—®æ—¶é—´
	type cacheItem struct {
		key       string
		size      int64
		createdAt time.Time
	}

	var items []cacheItem
	totalCurrentSize := int64(0)

	err := c.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()
			key := string(item.Key())

			// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
			if item.ExpiresAt() > 0 && item.ExpiresAt() < uint64(time.Now().Unix()) {
				continue // è·³è¿‡è¿‡æœŸçš„æ¡ç›®ï¼Œç¨åä¼šè¢«è‡ªåŠ¨æ¸…ç†
			}

			// ä¼°ç®—æ¡ç›®å¤§å°
			itemSize := item.EstimatedSize()
			totalCurrentSize += itemSize

			// å°è¯•è§£æåˆ›å»ºæ—¶é—´
			var createdAt time.Time
			err := item.Value(func(val []byte) error {
				var entry CacheEntry
				if parseErr := json.Unmarshal(val, &entry); parseErr == nil {
					createdAt = entry.CreatedAt
				} else {
					// å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ï¼ˆè¿™äº›æ¡ç›®ä¼šè¢«ä¼˜å…ˆæ¸…ç†ï¼‰
					createdAt = time.Now().Add(-24 * time.Hour)
				}
				return nil
			})

			if err == nil {
				items = append(items, cacheItem{
					key:       key,
					size:      itemSize,
					createdAt: createdAt,
				})
			}
		}
		return nil
	})

	if err != nil {
		return fmt.Errorf("æ”¶é›†ç¼“å­˜æ¡ç›®å¤±è´¥: %w", err)
	}

	// å¦‚æœå½“å‰å¤§å°å·²ç»å°äºç›®æ ‡å¤§å°ï¼Œæ— éœ€æ¸…ç†
	if totalCurrentSize <= targetSize {
		return nil
	}

	// æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ—§çš„åœ¨å‰é¢ï¼‰
	sort.Slice(items, func(i, j int) bool {
		return items[i].createdAt.Before(items[j].createdAt)
	})

	// è®¡ç®—éœ€è¦åˆ é™¤çš„å¤§å°
	needToDelete := totalCurrentSize - targetSize
	deletedSize := int64(0)
	keysToDelete := make([]string, 0)

	// é€‰æ‹©æœ€æ—§çš„æ¡ç›®è¿›è¡Œåˆ é™¤
	for _, item := range items {
		if deletedSize >= needToDelete {
			break
		}
		keysToDelete = append(keysToDelete, item.key)
		deletedSize += item.size
	}

	// æ‰¹é‡åˆ é™¤é€‰ä¸­çš„æ¡ç›®
	if len(keysToDelete) > 0 {
		err = c.db.Update(func(txn *badger.Txn) error {
			for _, key := range keysToDelete {
				if err := txn.Delete([]byte(key)); err != nil {
					return err
				}
			}
			return nil
		})

		if err != nil {
			return fmt.Errorf("æ‰¹é‡åˆ é™¤ç¼“å­˜æ¡ç›®å¤±è´¥: %w", err)
		}

		fs.Debugf(nil, "LRUæ¸…ç†: åˆ é™¤äº† %d ä¸ªæ¡ç›®ï¼Œé‡Šæ”¾çº¦ %d MB",
			len(keysToDelete), deletedSize>>20)
	}

	return nil
}

// GetCacheDir è·å–ç¼“å­˜ç›®å½•è·¯å¾„ - æ”¯æŒå¤šå®ä¾‹å…±äº«
func GetCacheDir(name string) string {
	// ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ç¼“å­˜ç›®å½• - æ‰€æœ‰å®ä¾‹å…±äº«åŒä¸€è·¯å¾„
	if userCacheDir, err := os.UserCacheDir(); err == nil {
		return filepath.Join(userCacheDir, "rclone", name)
	}

	// å›é€€åˆ°ä¸´æ—¶ç›®å½•
	return filepath.Join(os.TempDir(), "rclone_cache", name)
}

// CleanupExpiredCaches æ¸…ç†è¿‡æœŸçš„ç¼“å­˜ç›®å½•ï¼ˆå¯é€‰çš„ç»´æŠ¤åŠŸèƒ½ï¼‰
func CleanupExpiredCaches(basePath string, maxAge time.Duration) error {
	entries, err := os.ReadDir(basePath)
	if err != nil {
		return err
	}

	cutoff := time.Now().Add(-maxAge)
	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		info, err := entry.Info()
		if err != nil {
			continue
		}

		if info.ModTime().Before(cutoff) {
			cachePath := filepath.Join(basePath, entry.Name())
			fs.Debugf(nil, "æ¸…ç†è¿‡æœŸç¼“å­˜ç›®å½•: %s", cachePath)
			os.RemoveAll(cachePath)
		}
	}

	return nil
}

// isLockError æ£€æŸ¥é”™è¯¯æ˜¯å¦ä¸ºæ•°æ®åº“é”å®šé”™è¯¯ï¼ˆå¤šå®ä¾‹å†²çªï¼‰
func isLockError(err error) bool {
	if err == nil {
		return false
	}
	errStr := strings.ToLower(err.Error())
	// æ£€æŸ¥å¸¸è§çš„æ•°æ®åº“é”å®šé”™è¯¯ä¿¡æ¯
	lockKeywords := []string{
		"resource temporarily unavailable",
		"database is locked",
		"cannot acquire directory lock",
		"lock",
		"resource busy",
	}

	for _, keyword := range lockKeywords {
		if strings.Contains(errStr, keyword) {
			return true
		}
	}
	return false
}

// NullCache ç©ºç¼“å­˜å®ç°ï¼Œç”¨äºå¤šå®ä¾‹å†²çªæ—¶çš„é™çº§æ–¹æ¡ˆ
type NullCache struct {
	name     string
	basePath string
}

// NewNullCache åˆ›å»ºç©ºç¼“å­˜å®ä¾‹
func NewNullCache(name, basePath string) *NullCache {
	return &NullCache{
		name:     name,
		basePath: basePath,
	}
}

// Set ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Set(key string, value interface{}, ttl time.Duration) error {
	return nil // é™é»˜å¿½ç•¥
}

// Get ç©ºå®ç°ï¼Œæ€»æ˜¯è¿”å›æœªæ‰¾åˆ°
func (c *NullCache) Get(key string, result interface{}) (bool, error) {
	return false, nil // æ€»æ˜¯æœªæ‰¾åˆ°
}

// Delete ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Delete(key string) error {
	return nil // é™é»˜å¿½ç•¥
}

// DeletePrefix ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) DeletePrefix(prefix string) error {
	return nil // é™é»˜å¿½ç•¥
}

// Clear ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Clear() error {
	return nil // é™é»˜å¿½ç•¥
}

// Stats è¿”å›ç©ºç»Ÿè®¡ä¿¡æ¯
func (c *NullCache) Stats() map[string]interface{} {
	return map[string]interface{}{
		"name":       c.name + "_null",
		"lsm_size":   0,
		"vlog_size":  0,
		"total_size": 0,
		"type":       "null_cache",
	}
}

// ListAllKeys è¿”å›ç©ºé”®åˆ—è¡¨
func (c *NullCache) ListAllKeys() ([]string, error) {
	return []string{}, nil
}

// GetAllEntries è¿”å›ç©ºæ¡ç›®åˆ—è¡¨
func (c *NullCache) GetAllEntries() (map[string]interface{}, error) {
	return map[string]interface{}{}, nil
}

// GetKeysByPrefix è¿”å›ç©ºé”®åˆ—è¡¨
func (c *NullCache) GetKeysByPrefix(prefix string) ([]string, error) {
	return []string{}, nil
}

// Close ç©ºå®ç°ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ
func (c *NullCache) Close() error {
	return nil // é™é»˜å¿½ç•¥
}

// ğŸ”§ å†…å­˜å¤‡ä»½æ“ä½œæ–¹æ³•

// setToMemory å°†æ•°æ®ä¿å­˜åˆ°å†…å­˜å¤‡ä»½
func (c *BadgerCache) setToMemory(key string, value interface{}, ttl time.Duration) error {
	c.memoryMutex.Lock()
	defer c.memoryMutex.Unlock()

	// æ£€æŸ¥å†…å­˜æ¡ç›®æ•°é‡é™åˆ¶
	if len(c.memoryBackup) >= c.maxMemoryItems {
		// æ¸…ç†è¿‡æœŸæ¡ç›®
		c.cleanupExpiredMemoryEntries()

		// å¦‚æœä»ç„¶è¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
		if len(c.memoryBackup) >= c.maxMemoryItems {
			c.evictOldestMemoryEntry()
		}
	}

	// åˆ›å»ºç¼“å­˜æ¡ç›®
	entry := &CacheEntry{
		Key:       key,
		Value:     value,
		CreatedAt: time.Now(),
		ExpiresAt: time.Now().Add(ttl),
	}

	c.memoryBackup[key] = entry
	fs.Debugf(nil, "å†…å­˜å¤‡ä»½ä¿å­˜: %s (TTL: %v)", key, ttl)
	return nil
}

// getFromMemory ä»å†…å­˜å¤‡ä»½è·å–æ•°æ®
func (c *BadgerCache) getFromMemory(key string, result interface{}) (bool, error) {
	c.memoryMutex.RLock()
	defer c.memoryMutex.RUnlock()

	entry, exists := c.memoryBackup[key]
	if !exists {
		return false, nil
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(entry.ExpiresAt) {
		// å¼‚æ­¥åˆ é™¤è¿‡æœŸæ¡ç›®
		go func() {
			c.memoryMutex.Lock()
			delete(c.memoryBackup, key)
			c.memoryMutex.Unlock()
		}()
		return false, nil
	}

	// å°†å€¼ååºåˆ—åŒ–åˆ°resultä¸­
	valueData, err := json.Marshal(entry.Value)
	if err != nil {
		return false, fmt.Errorf("åºåˆ—åŒ–å†…å­˜ç¼“å­˜å€¼å¤±è´¥: %w", err)
	}

	if err := json.Unmarshal(valueData, result); err != nil {
		return false, fmt.Errorf("ååºåˆ—åŒ–å†…å­˜ç¼“å­˜å€¼å¤±è´¥: %w", err)
	}

	fs.Debugf(nil, "å†…å­˜å¤‡ä»½å‘½ä¸­: %s", key)
	return true, nil
}

// cleanupExpiredMemoryEntries æ¸…ç†è¿‡æœŸçš„å†…å­˜æ¡ç›®
func (c *BadgerCache) cleanupExpiredMemoryEntries() {
	now := time.Now()
	for key, entry := range c.memoryBackup {
		if now.After(entry.ExpiresAt) {
			delete(c.memoryBackup, key)
		}
	}
}

// evictOldestMemoryEntry åˆ é™¤æœ€æ—§çš„å†…å­˜æ¡ç›®
func (c *BadgerCache) evictOldestMemoryEntry() {
	var oldestKey string
	var oldestTime time.Time

	for key, entry := range c.memoryBackup {
		if oldestKey == "" || entry.CreatedAt.Before(oldestTime) {
			oldestKey = key
			oldestTime = entry.CreatedAt
		}
	}

	if oldestKey != "" {
		delete(c.memoryBackup, oldestKey)
		fs.Debugf(nil, "å†…å­˜å¤‡ä»½æ·˜æ±°æœ€æ—§æ¡ç›®: %s", oldestKey)
	}
}
